{
  "title": "訓練神經網絡，使用neuralnet套件",
  "navigation": "神經網絡",
  "label1": "請為虛擬變數進行虛擬編碼，請參見數據 > 計算虛擬變數（保留所有級別即1熱編碼）。縮放和中心化數值變數，請參見數據 > 標準化變數",
  "model": "輸入模型名稱",
  "dependentvar": "因變數",
  "independentvars": "自變數",
  "seed": "設置隨機種子",
  "iter": "學習的最大步數",
  "tf": "算法",
  "threshold": "閾值",
  "label2": "隱藏層數量及每個隱藏層的神經元數量",
  "layers": "指定每層的神經元數量，例如1。對於1層中的5個神經元，輸入5；對於第1層5個神經元，第2層6個神經元，第3層7個神經元，輸入5,6,7",
  "OutActFunc": "指定輸出激活函數",
  "rep": "神經網絡訓練的重複次數",
  "label3": "上學習率和下學習率的乘法因子",
  "minus": "上（減）",
  "upper": "下（加）",
  "lifesign": "在計算神經網絡過程中打印的程度設置",
  "lifesignstep": "在完整生命跡象模式下打印最小閾值的步長",
  "errfct": "用於計算誤差的可微函數",
  "linearoutput": "不應對輸出神經元應用激活函數",
  "likelihood": "似然性",
  "help": {
    "title": "訓練神經網絡，使用neuralnet套件",
    "r_help": "help(neuralnet, package='neuralnet')",
    "body": "\n            <b>注意</b></br>\n            當指定單一因變數時，它可以是數值型或因子型。如果指定的因變數是因子型，我們會自動使用RSNNS套件中的decode函數進行虛擬編碼，使用一熱編碼。</br></br>\n            此外，如果您使用一熱編碼來虛擬編碼因子變數，您可以在對話框中指定多個因變數。在這種情況下，因變數必須是數值型。</br></br>\n            您可以使用\"數據 > 計算虛擬變數\"，選擇“保留所有級別”設置以獲得一熱編碼。</br></br>\n            對於因子型的因變數，當使用構建的模型對數據集進行評分時，我們將顯示混淆矩陣、ROC和模型準確性統計。生成的預測是因子型，因為我們預測類別。這些將與預測概率一起保存在數據集中。</br></br>\n            當有虛擬編碼的因變數時，我們將不會在使用構建的模型對數據集進行評分時顯示混淆矩陣、ROC和模型準確性統計。然而，預測將在對數據集進行評分時保存在數據集中。預測是與虛擬編碼因變數相關的概率。</br></br>\n            通常最好標準化自變數（它們也必須是數值型）。請參見“數據 > 標準化變數”。</br></br>\n            如果您有類別型自變數，請使用一熱編碼來虛擬編碼因子變數。</br></br>\n            <b>描述</b></br>\n            使用反向傳播、彈性反向傳播（RPROP）進行神經網絡訓練（Riedmiller, 1994）或不進行權重回溯（Riedmiller和Braun, 1993）或由Anastasiadis等人（2005）提出的修改後全局收斂版本（GRPROP）。該函數通過自定義選擇誤差和激活函數允許靈活設置。此外，實現了廣義權重的計算（Intrator O.和Intrator N., 1993）。\n            <b>用法</b>\n            <br/>\n            <code> \n            neuralnet(formula, data, hidden = 1, threshold = 0.01,\n              stepmax = 1e+05, rep = 1, startweights = NULL,\n              learningrate.limit = NULL, learningrate.factor = list(minus = 0.5,\n              plus = 1.2), learningrate = NULL, lifesign = \"none\",\n              lifesign.step = 1000, algorithm = \"rprop+\", err.fct = \"sse\",\n              act.fct = \"logistic\", linear.output = TRUE, exclude = NULL,\n              constant.weights = NULL, likelihood = FALSE)\n            </code> <br/>\n            <b>參數</b><br/>\n            <ul>\n            <li>\n            formula: 擬合模型的符號描述。\n            </li>\n            <li>\n            data: 包含公式中指定變數的數據框。\n            </li>\n            <li>\n            hidden: 一個整數向量，指定每層的隱藏神經元（頂點）數量。\n            </li>\n            <li>\n            threshold: 一個數值，指定作為停止標準的誤差函數的偏導數的閾值。\n            </li>\n            <li>\n            stepmax: 神經網絡訓練的最大步數。達到此最大值將導致神經網絡的訓練過程停止。\n            </li>\n            <li>\n            rep: 神經網絡訓練的重複次數。\n            </li>\n            <li>\n            startweights: 一個包含權重起始值的向量。設置為NULL以進行隨機初始化。\n            </li>\n            <li>\n            learningrate.limit: 一個向量或列表，包含學習率的最低和最高限制。僅用於RPROP和GRPROP。</li>\n            <li>\n            learningrate.factor: 一個向量或列表，包含上學習率和下學習率的乘法因子。僅用於RPROP和GRPROP。\n            </li>\n            <li>\n            learningrate: 一個數值，指定傳統反向傳播使用的學習率。僅用於傳統反向傳播。\n            </li>\n            <li>\n            lifesign: 一個字符串，指定在計算神經網絡過程中將打印多少信息。'none'、'minimal'或'full'。\n            </li>\n            <li>\n            lifesign.step: 一個整數，指定在完整生命跡象模式下打印最小閾值的步長。\n            </li>\n            <li>\n            algorithm: 一個字符串，包含計算神經網絡的算法類型。可能的類型有：'backprop'、'rprop+'、'rprop-'、'sag'或'slr'。'backprop'指反向傳播，'rprop+'和'rprop-'指帶和不帶權重回溯的彈性反向傳播，而'sag'和'slr'則引入使用修改後的全局收斂算法（grprop）。有關更多信息，請參見詳細信息。\n            </li>\n            <li>\n            err.fct: 用於計算誤差的可微函數。或者，可以使用字符串'sse'和'ce'，分別表示平方誤差和交叉熵。\n            </li>\n            <li>\n            act.fct: 用於平滑協變量或神經元與權重的交叉乘積結果的可微函數。此外，'logistic'和'tanh'字符串也可以用於邏輯函數和雙曲正切函數。\n            </li>\n            <li>\n            linear.output: 邏輯。如果不應將act.fct應用於輸出神經元，則將linear output設置為TRUE，否則設置為FALSE。\n            </li>\n            <li>\n            exclude: 一個向量或矩陣，指定在計算中排除的權重。如果作為向量給出，則必須知道權重的確切位置。具有n行和3列的矩陣將排除n個權重，其中第一列表示層，第二列表示輸入神經元，第三列表示權重的輸出神經元。\n            </li>\n            <li>\n            constant.weights: 一個向量，指定在訓練過程中排除的權重值，並視為固定。\n            </li>\n            <li>\n            likelihood: 邏輯。如果誤差函數等於負對數似然函數，則將計算信息準則AIC和BIC。此外，使用confidence.interval是有意義的。\n            </li>\n            </ul>\n            <b>詳細信息</b><br/>\n            全局收斂算法基於不進行權重回溯的彈性反向傳播，並額外修改一個學習率，無論是與最小絕對梯度相關的學習率（sag）還是最小學習率（slr）本身。grprop算法中的學習率限制在learningrate.limit中定義的邊界內。\n            ​<b>值</b><br/>\n            neuralnet返回一個nn類的對象。nn類的對象是一個包含最多以下組件的列表：<br/>\n            call: 匹配的調用。<br/>\n            response: 從數據參數中提取。<br/>\n            covariate: 從數據參數中提取的變數。<br/>\n            model.list: 一個包含從公式參數中提取的協變量和響應變數的列表。<br/>\n            err.fct: 誤差函數。<br/>\n            act.fct: 激活函數。<br/>\n            data: 數據參數。<br/>\n            net.result: 一個列表，包含每次重複的神經網絡的整體結果。<br/>\n            weights: 一個列表，包含每次重複的神經網絡的擬合權重。<br/>\n            generalized.weights: 一個列表，包含每次重複的神經網絡的廣義權重。<br/>\n            result.matrix: 一個矩陣，包含每次重複的達到的閾值、所需步數、誤差、AIC和BIC（如果計算）及權重。每列代表一次重複。<br/>\n            startweights: 一個列表，包含每次重複的神經網絡的起始權重。<br/>\n            ​<b>示例</b><br/>\n            <code> \n            ​library(neuralnet)\n            ​# 二元分類\n            nn <- neuralnet(Species == \"setosa\" ~ Petal.Length + Petal.Width, iris, linear.output = FALSE)\n            ## 不執行: print(nn)\n            ## 不執行: plot(nn)\n            # 多類別分類\n            nn <- neuralnet(Species ~ Petal.Length + Petal.Width, iris, linear.output = FALSE)\n            ## 不執行: print(nn)\n            ## 不執行: plot(nn)\n            # 自定義激活函數\n            softplus <- function(x) log(1 + exp(x))\n            nn <- neuralnet((Species == \"setosa\") ~ Petal.Length + Petal.Width, iris, \n                            linear.output = FALSE, hidden = c(3, 2), act.fct = softplus)\n            ## 不執行: print(nn)\n            ## 不執行: plot(nn)\n            </code> <br/>\n            <b>套件</b></br>\n            neuralnet;NeuralNetTools</br>\n            <b>幫助</b></br>\n            有關詳細幫助，請單擊此對話框覆蓋右上角的R圖標，或在R語法編輯器中運行以下命令</br>\n            help(neuralnet, package='neuralnet')\n\t\t\t"
  }
}
{
  "title": "Çok Katmanlı Algılayıcı, RSNNS paketi kullanarak",
  "navigation": "Çok Katmanlı Algılayıcı",
  "label1": "LÜTFEN DUMMY KODU FAKTÖR DEĞİŞKENLERİ, VERİ > DUMMY DEĞİŞKENLERİ HESAPLA'YI GÖRÜN (TÜM SEVİYELERİ KORUYUN A.K.A 1 Sıcak Kodlama). SAYISAL DEĞİŞKENLERİ ÖLÇEKLENDİRİN VE MERKEZİLEŞTİRİN, VERİ > DEĞİŞKENLERİ STANDARDİZE ET'İ GÖRÜN",
  "model": "Bir model adı girin",
  "dependentvar": "Bağımlı değişken",
  "independentvars": "Bağımsız değişken(ler)",
  "seed": "Tohum ayarla",
  "iter": "Öğrenme için maksimum iterasyon",
  "tf": "Öğrenme fonksiyonu",
  "label2": "Gizli katman sayısı ve her gizli katmandaki nöron sayısı",
  "layers": "Her katmandaki nöron sayısını belirtin, örneğin 1. 1 katmanda 5 nöron için 5 girin. 1. katmanda 5 nöron, 2. katmanda 6 nöron, 3. katmanda 7 nöron için 5,6,7 girin",
  "learnfuncparams": "Öğrenme fonksiyonu parametreleri",
  "help": {
    "title": "Çok Katmanlı Algılayıcı, RSNNS paketi kullanarak",
    "r_help": "help(mlp, package ='RSNNS')",
    "body": "\n            <b>NOT</b></br>\n            Tek bir bağımlı değişken belirttiğinizde, bu sayısal veya faktör olabilir. Belirtilen bağımlı değişken bir faktörse, faktör değişkenini otomatik olarak one-hot Kodlama kullanarak dummy kodlarız, RSNNS paketindeki decode fonksiyonunu kullanarak.</br></br>\n            Ayrıca, bir faktör değişkenini dummy kodlamak için one-hot kodlama kullanıyorsanız, diyalogda birden fazla bağımlı değişken belirtebilirsiniz. Bu durumda, bağımlı değişkenler sayısal türde olmalıdır.</br></br>\n            \"Veri > Dummy değişkenleri hesapla\" seçeneğini kullanarak, \"Tüm seviyeleri koru\" ayarını seçerek one-hot kodlama alabilirsiniz.</br></br>\n            Faktör türündeki bağımlı değişkenler için, oluşturulan model kullanılarak bir veri kümesini puanlarken bir karışıklık matrisini, ROC'yu ve model doğruluk istatistiklerini görüntüleyeceğiz. Üretilen tahminler faktör türündedir çünkü sınıfı tahmin ediyoruz. Bu tahminler, puanlama sırasında tahmin edilen olasılıklarla birlikte veri kümesine kaydedilecektir.</br></br>\n            Dummy kodlanmış bağımlı değişkenler olduğunda, oluşturulan model kullanılarak bir veri kümesini puanlarken bir karışıklık matrisini, ROC'yu ve model doğruluk istatistiklerini görüntülemeyeceğiz. Ancak, tahminler veri kümesini puanlarken veri kümesine kaydedilecektir. Tahminler, dummy kodlanmış bağımlı değişkenlerle ilişkili olasılıklardır.</br></br>\n            Bağımsız değişkenleri standartlaştırmak genellikle en iyisidir (bunlar da sayısal olmalıdır). \"Veri > Değişkenleri standartlaştır\" seçeneğine bakın.</br></br>\n            Kategorik bağımsız değişkenleriniz varsa, faktör değişkenlerini dummy kodlamak için one-hot kodlama kullanın.</br></br>\n            <b>Açıklama</b></br>\n            Bu fonksiyon bir çok katmanlı algılayıcı (MLP) oluşturur ve eğitir. MLP'ler tamamen bağlı ileri beslemeli ağlardır ve muhtemelen en yaygın ağ mimarisidir. Eğitim genellikle hata geri yayılımı veya ilgili bir prosedürle gerçekleştirilir.</br>\n            SNNS'de bu fonksiyonla birlikte kullanılabilecek birçok farklı öğrenme fonksiyonu vardır, örneğin, Std_Backpropagation, BackpropBatch, BackpropChunk, BackpropMomentum, BackpropWeightDecay, Rprop, Quickprop, SCG (ölçekli konjugat gradyan), ...</br>\n            <b>Kullanım</b>\n            <br/>\n            <code> \n            mlp(x, ...)<br/>\n            ## Varsayılan S3 yöntemi:<br/>\n            mlp(x, y, size = c(5), maxit = 100,\n              initFunc = \"Randomize_Weights\", initFuncParams = c(-0.3, 0.3),\n              learnFunc = \"Std_Backpropagation\", learnFuncParams = c(0.2, 0),\n              updateFunc = \"Topological_Order\", updateFuncParams = c(0),\n              hiddenActFunc = \"Act_Logistic\", shufflePatterns = TRUE,\n              linOut = FALSE, outputActFunc = if (linOut) \"Act_Identity\" else\n              \"Act_Logistic\", inputsTest = NULL, targetsTest = NULL,\n              pruneFunc = NULL, pruneFuncParams = NULL, ...)\n            </code> <br/>\n            <b>Argümanlar</b><br/>\n            <ul>\n            <li>\n            x: ağ için eğitim girdileri içeren bir matris\n            </li>\n            <li>\n            ... : ek fonksiyon parametreleri (şu anda kullanılmıyor)\n            </li>\n            <li>\n            y: karşılık gelen hedef değerler\n            </li>\n            <li>\n            size: gizli katman(lar)daki birim sayısı\n            </li>\n            <li>\n            maxit: öğrenme için maksimum iterasyon\n            </li>\n            <li>\n            initFunc: kullanılacak başlatma fonksiyonu\n            </li>\n            <li>\n            initFuncParams: başlatma fonksiyonu için parametreler\n            </li>\n            <li>\n            learnFunc: kullanılacak öğrenme fonksiyonu\n            </li>\n            <li>\n            learnFuncParams: öğrenme fonksiyonu için parametreler\n            </li>\n            <li>\n            updateFunc: kullanılacak güncelleme fonksiyonu\n            </li>\n            <li>\n            updateFuncParams: güncelleme fonksiyonu için parametreler\n            </li>\n            <li>\n            hiddenActFunc: tüm gizli birimlerin aktivasyon fonksiyonu\n            </li>\n            <li>\n            shufflePatterns: desenlerin karıştırılıp karıştırılmayacağı?\n            </li>\n            <li>\n            linOut: çıkış birimlerinin aktivasyon fonksiyonunu lineer veya lojistik olarak ayarlar (outputActFunc verilirse göz ardı edilir)\n            </li>\n            <li>\n            outputActFunc: tüm çıkış birimlerinin aktivasyon fonksiyonu\n            </li>\n            <li>\n            inputsTest: ağı test etmek için bir matris\n            </li>\n            <li>\n            targetsTest: test girişi için karşılık gelen hedefler\n            </li>\n            <li>\n            pruneFunc: kullanılacak budama fonksiyonu\n            </li>\n            <li>\n            pruneFuncParams: budama fonksiyonu için parametreler. Diğer fonksiyonlardan farklı olarak, bunlar adlandırılmış bir listede verilmelidir. Daha fazla açıklama için budama demolarına bakın.\n            </li>\n            </ul>\n            <b>Ayrıntılar</b></br>\n            Std_Backpropagation, BackpropBatch gibi, iki parametreye sahiptir, öğrenme oranı ve maksimum çıktı farkı. Öğrenme oranı genellikle 0.1 ile 1 arasında bir değerdir. Gradyan iniş adım genişliğini belirtir. Maksimum fark, çıktı ve hedef değeri arasındaki ne kadar farkın sıfır hata olarak kabul edileceğini ve geri yayılmayacağını tanımlar. Bu parametre aşırı eğitimden kaçınmak için kullanılır. Tüm öğrenme fonksiyonlarının parametrelerinin tam listesi için SNNS Kullanıcı Kılavuzu'na bakın, s. 67.</br>\n            Başlatma ve güncelleme fonksiyonları için ayarlanan varsayılanlar genellikle değiştirilmesine gerek yoktur.</br>\n            <b>Değer</b><br/>\n            bir rsnns nesnesi.\n            <b>Kaynaklar</b><br/>\n            Rosenblatt, F. (1958), 'Algılayıcı: Beyinde bilgi depolama ve organizasyonu için olasılıksal bir model', Psikolojik İnceleme 65(6), 386–408.<br/>\n            Rumelhart, D. E.; Clelland, J. L. M. & Grup, P. R. (1986), Paralel dağıtılmış işleme: bilişin mikro yapısındaki keşifler, Mit, Cambridge, MA vb.<br/>\n            Zell, A. ve diğerleri (1998), 'SNNS Stuttgart Sinir Ağı Simülatörü Kullanıcı Kılavuzu, Versiyon 4.2', IPVR, Stuttgart Üniversitesi ve WSI, Tübingen Üniversitesi.<br/> http://www.ra.cs.uni-tuebingen.de/SNNS/welcome.html<br/>\n            Zell, A. (1994), Sinir Ağlarının Simülasyonu, Addison-Wesley. (Almanca)<br/>\n            <b>Örnekler</b><br/>\n            <code> \n            data(iris)<br/>\n            #vektörü karıştır<br/>\n            iris <- iris[sample(1:nrow(iris),length(1:nrow(iris))),1:ncol(iris)]<br/>\n            irisValues <- iris[,1:4]<br/>\n            irisTargets <- decodeClassLabels(iris[,5])<br/>\n            #irisTargets <- decodeClassLabels(iris[,5], valTrue=0.9, valFalse=0.1)<br/>\n            iris <- splitForTrainingAndTest(irisValues, irisTargets, ratio=0.15)<br/>\n            iris <- normTrainingAndTestSet(iris)<br/>\n            model <- mlp(iris$inputsTrain, iris$targetsTrain, size=5, learnFuncParams=c(0.1),\n                          maxit=50, inputsTest=iris$inputsTest, targetsTest=iris$targetsTest)<br/>\n            summary(model)<br/>\n            model<br/>\n            weightMatrix(model)<br/>\n            extractNetInfo(model)<br/>\n            par(mfrow=c(2,2))<br/>\n            plotIterativeError(model)<br/>\n            predictions <- predict(model,iris$inputsTest)<br/>\n            plotRegressionError(predictions[,2], iris$targetsTest[,2])<br/>\n            confusionMatrix(iris$targetsTrain,fitted.values(model))<br/>\n            confusionMatrix(iris$targetsTest,predictions)<br/>\n            plotROC(fitted.values(model)[,2], iris$targetsTrain[,2])<br/>\n            plotROC(predictions[,2], iris$targetsTest[,2])<br/>\n            #402040 yöntemi ile karışıklık matris<br/>\n            confusionMatrix(iris$targetsTrain, encodeClassLabels(fitted.values(model),\n                                                                   method=\"402040\", l=0.4, h=0.6))<br/>\n            </code> <br/>\n            <b>Paket</b></br>\n            RSNNS;NeuralNetTools</br>\n            <b>Yardım</b></br>\n            Ayrıntılı yardım için bu diyalog üst katmanındaki R simgesine tıklayın veya R sözdizimi editöründe aşağıdaki komutu çalıştırın</br>\n            help(mlp, package ='RSNNS')\n\t\t\t"
  }
}
{
  "title": "多層感知器，使用 RSNNS 套件",
  "navigation": "多層感知器",
  "label1": "請對虛擬變數進行虛擬編碼，請參見數據 > 計算虛擬變數（保留所有級別即 1 熱編碼）。縮放和中心化數值變數，請參見數據 > 標準化變數",
  "model": "輸入模型名稱",
  "dependentvar": "因變數",
  "independentvars": "自變數",
  "seed": "設置隨機種子",
  "iter": "最大學習迭代次數",
  "tf": "學習函數",
  "label2": "隱藏層數量及每個隱藏層的神經元數量",
  "layers": "指定每層的神經元數量，例如 1。對於 1 層中的 5 個神經元，輸入 5；對於第 1 層 5 個神經元，第 2 層 6 個神經元，第 3 層 7 個神經元，輸入 5,6,7",
  "learnfuncparams": "學習函數參數",
  "help": {
    "title": "多層感知器，使用 RSNNS 套件",
    "r_help": "help(mlp, package ='RSNNS')",
    "body": "\n            <b>注意</b></br>\n            當您指定單一因變數時，它可以是數值型或因子型。如果指定的因變數是因子型，我們會自動使用 RSNNS 套件中的 decode 函數進行虛擬編碼，使用一熱編碼。</br></br>\n            此外，如果您使用一熱編碼對因子變數進行虛擬編碼，您可以在對話框中指定多個因變數。在這種情況下，因變數必須是數值型。</br></br>\n            您可以使用 \"數據 > 計算虛擬變數\"，選擇 \"保留所有級別\" 設置以獲得一熱編碼。</br></br>\n            對於因子型的因變數，我們在使用構建的模型對數據集進行評分時，將顯示混淆矩陣、ROC 和模型準確性統計數據。生成的預測為因子型，因為我們預測類別。這些將與預測概率一起保存在數據集中。</br></br>\n            當存在虛擬編碼的因變數時，我們在使用構建的模型對數據集進行評分時不會顯示混淆矩陣、ROC 和模型準確性統計數據。然而，預測將在對數據集進行評分時保存在數據集中。預測是與虛擬編碼的因變數相關的概率。</br></br>\n            通常最好標準化自變數（它們也必須是數值型），請參見 \"數據 > 標準化變數\"。</br></br>\n            如果您有類別型自變數，請使用一熱編碼對因子變數進行虛擬編碼。</br></br>\n            <b>描述</b></br>\n            此函數創建一個多層感知器（MLP）並對其進行訓練。MLP 是完全連接的前饋網絡，可能是最常用的網絡架構。訓練通常通過誤差反向傳播或相關程序進行。</br>\n            SNNS 中有許多不同的學習函數可以與此函數一起使用，例如 Std_Backpropagation、BackpropBatch、BackpropChunk、BackpropMomentum、BackpropWeightDecay、Rprop、Quickprop、SCG（縮放共軛梯度）等。</br>\n            <b>用法</b>\n            <br/>\n            <code> \n            mlp(x, ...)<br/>\n            ## 默認 S3 方法:<br/>\n            mlp(x, y, size = c(5), maxit = 100,\n              initFunc = \"Randomize_Weights\", initFuncParams = c(-0.3, 0.3),\n              learnFunc = \"Std_Backpropagation\", learnFuncParams = c(0.2, 0),\n              updateFunc = \"Topological_Order\", updateFuncParams = c(0),\n              hiddenActFunc = \"Act_Logistic\", shufflePatterns = TRUE,\n              linOut = FALSE, outputActFunc = if (linOut) \"Act_Identity\" else\n              \"Act_Logistic\", inputsTest = NULL, targetsTest = NULL,\n              pruneFunc = NULL, pruneFuncParams = NULL, ...)\n            </code> <br/>\n            <b>參數</b><br/>\n            <ul>\n            <li>\n            x: 用於網絡的訓練輸入矩陣\n            </li>\n            <li>\n            ... : 額外的函數參數（目前未使用）\n            </li>\n            <li>\n            y: 對應的目標值\n            </li>\n            <li>\n            size: 隱藏層中的單元數量\n            </li>\n            <li>\n            maxit: 最大學習迭代次數\n            </li>\n            <li>\n            initFunc: 要使用的初始化函數\n            </li>\n            <li>\n            initFuncParams: 初始化函數的參數\n            </li>\n            <li>\n            learnFunc: 要使用的學習函數\n            </li>\n            <li>\n            learnFuncParams: 學習函數的參數\n            </li>\n            <li>\n            updateFunc: 要使用的更新函數\n            </li>\n            <li>\n            updateFuncParams: 更新函數的參數\n            </li>\n            <li>\n            hiddenActFunc: 所有隱藏單元的激活函數\n            </li>\n            <li>\n            shufflePatterns: 模式是否應該被打亂？\n            </li>\n            <li>\n            linOut: 將輸出單元的激活函數設置為線性或邏輯（如果給定 outputActFunc 則忽略）\n            </li>\n            <li>\n            outputActFunc: 所有輸出單元的激活函數\n            </li>\n            <li>\n            inputsTest: 用於測試網絡的輸入矩陣\n            </li>\n            <li>\n            targetsTest: 測試輸入的對應目標\n            </li>\n            <li>\n            pruneFunc: 要使用的修剪函數\n            </li>\n            <li>\n            pruneFuncParams: 修剪函數的參數。與其他函數不同，這些必須以命名列表的形式給出。請參見修剪演示以獲取進一步說明。\n            </li>\n            </ul>\n            <b>詳細信息</b></br>\n            Std_Backpropagation、BackpropBatch 等有兩個參數，學習率和最大輸出差異。學習率通常是 0.1 到 1 之間的值。它指定了梯度下降的步長。最大差異定義了輸出和目標值之間的差異被視為零誤差的程度，並且不會反向傳播。此參數用於防止過度訓練。要獲取所有學習函數的參數的完整列表，請參見 SNNS 用戶手冊，第 67 頁。</br>\n            通常不需要更改為初始化和更新函數設置的默認值。</br>\n            <b>返回值</b><br/>\n            一個 rsnns 對象。\n            <b>參考文獻</b><br/>\n            Rosenblatt, F. (1958), '感知器：一種用於信息存儲和組織的概率模型', 心理學評論 65(6), 386–408.<br/>\n            Rumelhart, D. E.; Clelland, J. L. M. & Group, P. R. (1986), 平行分佈處理：認知微結構的探索, Mit, 劍橋, MA 等等.<br/>\n            Zell, A. 等 (1998), 'SNNS 斯圖加特神經網絡模擬器用戶手冊, 版本 4.2', IPVR, 斯圖加特大學和圖賓根大學 WSI.<br/> http://www.ra.cs.uni-tuebingen.de/SNNS/welcome.html<br/>\n            Zell, A. (1994), 模擬神經網絡, Addison-Wesley.（德文）<br/>\n            <b>示例</b><br/>\n            <code> \n            data(iris)<br/>\n            #打亂向量<br/>\n            iris <- iris[sample(1:nrow(iris),length(1:nrow(iris))),1:ncol(iris)]<br/>\n            irisValues <- iris[,1:4]<br/>\n            irisTargets <- decodeClassLabels(iris[,5])<br/>\n            #irisTargets <- decodeClassLabels(iris[,5], valTrue=0.9, valFalse=0.1)<br/>\n            iris <- splitForTrainingAndTest(irisValues, irisTargets, ratio=0.15)<br/>\n            iris <- normTrainingAndTestSet(iris)<br/>\n            model <- mlp(iris$inputsTrain, iris$targetsTrain, size=5, learnFuncParams=c(0.1),\n                          maxit=50, inputsTest=iris$inputsTest, targetsTest=iris$targetsTest)<br/>\n            summary(model)<br/>\n            model<br/>\n            weightMatrix(model)<br/>\n            extractNetInfo(model)<br/>\n            par(mfrow=c(2,2))<br/>\n            plotIterativeError(model)<br/>\n            predictions <- predict(model,iris$inputsTest)<br/>\n            plotRegressionError(predictions[,2], iris$targetsTest[,2])<br/>\n            confusionMatrix(iris$targetsTrain,fitted.values(model))<br/>\n            confusionMatrix(iris$targetsTest,predictions)<br/>\n            plotROC(fitted.values(model)[,2], iris$targetsTrain[,2])<br/>\n            plotROC(predictions[,2], iris$targetsTest[,2])<br/>\n            #使用 402040 方法的混淆矩陣<br/>\n            confusionMatrix(iris$targetsTrain, encodeClassLabels(fitted.values(model),\n                                                                   method=\"402040\", l=0.4, h=0.6))<br/>\n            </code> <br/>\n            <b>套件</b></br>\n            RSNNS;NeuralNetTools</br>\n            <b>幫助</b></br>\n            有關詳細幫助，請單擊此對話框覆蓋右上角的 R 圖標或在 R 語法編輯器中運行以下命令</br>\n            help(mlp, package ='RSNNS')\n\t\t\t"
  }
}
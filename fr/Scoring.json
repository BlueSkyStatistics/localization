{
  "title": "Évaluer un ensemble de données à l'aide d'un modèle",
  "navigation": "Évaluation du modèle",
  "filterModels": "Filtrer les modèles par classe",
  "modelSelection": "Sélectionnez un modèle pour évaluer un ensemble de données",
  "label1": "Tests diagnostiques",
  "levelOfInterest": "Lorsque la variable à prédire a 2 niveaux, spécifiez le niveau d'intérêt. La matrice de confusion et les statistiques associées sont affichées avec le niveau d'intérêt spécifié comme référence.",
  "label12": "Résultats des tests : Dès qu'un modèle est sélectionné, nous effectuerons des tests pour voir si les variables dépendantes spécifiées dans le modèle sont disponibles dans l'ensemble de données à évaluer. Les résultats seront affichés ici.",
  "label2": "Enregistrer les valeurs prédites et les statistiques de soutien.",
  "label3": "Les prédictions et les probabilités prédites, le cas échéant, sont stockées dans l'ensemble de données évalué en tant que nouvelles variables avec le préfixe ci-dessous.",
  "label4": "**Pour les variables dépendantes avec 2 niveaux, le 2ème niveau est considéré comme le niveau positif. Voir Données > Niveaux de facteur > Réorganiser les niveaux manuellement pour changer l'ordre des niveaux de facteur et reconstruire le modèle.",
  "conflevel": "Enregistrer les intervalles de confiance et de prédiction pour les valeurs prédites individuelles **(Valide uniquement pour les modèles linéaires (classe lm))",
  "rocCurves": "Afficher les courbes ROC (**Pour les variables dépendantes binaires uniquement)",
  "roctable": "Afficher le tableau ROC (**Pour les variables dépendantes binaires uniquement)",
  "saveRoctableToDataset": "Enregistrer le tableau ROC dans un ensemble de données (**Pour les variables dépendantes binaires uniquement)",
  "label6": "**Cocher la case ci-dessus entraînera une pénalité de performance pour les grands ensembles de données.",
  "colname": "Spécifiez le préfixe du nom de colonne",
  "datasetNameForROC": "Entrez un nom d'ensemble de données pour stocker les valeurs dans le tableau ROC.",
  "label5": "**Cocher la case ci-dessus entraînera une pénalité de performance pour les grands ensembles de données.",
  "level": "Spécifiez le niveau de confiance",
  "confusioncheck": "Générer la matrice de confusion",
  "help": {
    "title": "Évaluer un ensemble de données à l'aide d'un modèle",
    "r_help": "help(predict, package='stats')",
    "body": "\n    <b>Description</b></br>\n    L'évaluation du modèle fait ce qui suit</br>\n    1. Évalue l'ensemble de données actuel à l'aide du modèle préconstruit sélectionné. Stocke les prédictions avec l'intervalle de confiance spécifié dans l'ensemble de données actuel en utilisant le préfixe spécifié.</br>\n    2. Crée éventuellement une matrice de confusion et une courbe ROC</br>\n    3. Dans le cas où vous évaluez un ensemble de données d'entraînement contenant la variable dépendante/variable à prédire et que la variable dépendante a 2 niveaux, vous avez la possibilité de sélectionner le niveau de référence/niveau d'intérêt.<br/>\n    4. La matrice de confusion et les statistiques associées sont créées en utilisant le niveau d'intérêt spécifié.<br/>\n    Voir les détails sur la fonction de prédiction et la matrice de confusion ci-dessous\n    <br/>\n    <br/>\n    <b>Description</b></br>\n    predict est une fonction générique pour faire des prédictions à l'aide du modèle sélectionné. \n    <br/>\n    <b>Utilisation</b>\n    <br/>\n    <code> \n    BSkyPredict(modelname, prefix, datasetname)\n    </code> <br/>\n    <b>Arguments</b><br/>\n    <ul>\n    <li>\n    modelname: un objet modèle pour lequel une prédiction est souhaitée.\n    </li>\n    <li>\n    prefix: chaîne de préfixe qui sera utilisée pour créer de nouvelles variables contenant les prédictions.\n    </li>\n    <li>\n    datasetname: est l'ensemble de données actuel à évaluer et à enregistrer les prédictions.\n    </li>\n    </ul>\n    <b>Détails</b></br>\n    Stocke les prédictions avec l'intervalle de confiance spécifié dans l'ensemble de données actuel en utilisant le préfixe spécifié.</br>\n    <b>Paquet</b></br>\n    stats</br>\n    <b>Aide</b></br>\n    Pour une aide détaillée, cliquez sur l'icône R en haut à droite de cette superposition de dialogue ou exécutez la commande suivante help(predict, package ='stats') dans la fenêtre de l'éditeur R\n    </br>\n    </br>\n    <b>Description</b></br>\n    Crée une matrice de confusion en croisant les classes observées et prédites avec les statistiques associées. \n    <br/>\n    <b>Utilisation</b>\n    <br/>\n    <code> \n    BSkyConfusionMartix(modelname,showCofusionMatrix,predictions,datasetname)\n    </code> <br/>\n    <b>Arguments</b><br/>\n    <ul>\n    <li>\n    modelname : un objet modèle pour lequel une matrice de confusion est souhaitée.\n    </li>\n    <li>\n    showCofusionMatrix:  logique, si VRAI, la matrice de confusion est générée (si cela s'applique), si FAUX, la matrice de confusion n'est pas générée.\n    </li>\n    <li>\n    predictions : un objet qui est retourné comme résultat de l'appel predict().\n    </li>\n    <li>\n    datasetname: est le nom de l'ensemble de données actuel que nous voulons utiliser pour faire des prédictions.\n    </li>\n    </ul>\n    <b>Détails</b></br>\n    Affiche la matrice de confusion en utilisant la fonction confusionMatrix dans le paquet caret</br>\n    <b>Paquet</b></br>\n    caret</br>\n    <b>Aide</b></br>\n    Pour une aide détaillée, cliquez sur l'icône R en haut à droite de cette superposition de dialogue ou exécutez la commande suivante help(confusionMatrix, package ='caret') dans la fenêtre de l'éditeur R\n                "
  }
}
{
  "title": "多层感知器，使用RSNNS包",
  "navigation": "多层感知器",
  "label1": "请对因子变量进行虚拟编码，参见数据 > 计算虚拟变量（保留所有级别即1热编码）。缩放和中心化数值变量，参见数据 > 标准化变量",
  "model": "输入模型名称",
  "dependentvar": "因变量",
  "independentvars": "自变量",
  "seed": "设置种子",
  "iter": "最大学习迭代次数",
  "tf": "学习函数",
  "label2": "隐藏层数量及每个隐藏层的神经元数量",
  "layers": "指定每层的神经元数量，例如1。对于1层中的5个神经元，输入5；对于第1层5个神经元，第2层6个神经元，第3层7个神经元，输入5,6,7",
  "learnfuncparams": "学习函数参数",
  "help": {
    "title": "多层感知器，使用RSNNS包",
    "r_help": "help(mlp, package ='RSNNS')",
    "body": "\n            <b>注意</b></br>\n            当您指定一个因变量时，它可以是数值型或因子型。如果指定的因变量是因子型，我们会使用RSNNS包中的解码函数自动进行虚拟编码，采用一热编码。</br></br>\n            此外，如果您使用一热编码对因子变量进行虚拟编码，您可以在对话框中指定多个因变量。在这种情况下，因变量必须是数值型。</br></br>\n            您可以使用“数据 > 计算虚拟变量”，选择“保留所有级别”设置以获得一热编码。</br></br>\n            对于因子型的因变量，当使用构建的模型对数据集进行评分时，我们将显示混淆矩阵、ROC和模型准确性统计信息。生成的预测为因子型，因为我们预测的是类别。这些将与预测概率一起保存在数据集中。</br></br>\n            当存在虚拟编码的因变量时，我们在使用构建的模型对数据集进行评分时将不显示混淆矩阵、ROC和模型准确性统计信息。然而，预测将在评分数据集时保存在数据集中。预测是与虚拟编码因变量相关的概率。</br></br>\n            通常最好对自变量进行标准化（它们也必须是数值型），请参见“数据 > 标准化变量”。</br></br>\n            如果您有分类自变量，请使用一热编码对因子变量进行虚拟编码。</br></br>\n            <b>描述</b></br>\n            此函数创建一个多层感知器（MLP）并对其进行训练。MLP是完全连接的前馈网络，可能是使用中最常见的网络架构。训练通常通过误差反向传播或相关程序进行。</br>\n            SNNS中存在许多不同的学习函数，可以与此函数一起使用，例如Std_Backpropagation、BackpropBatch、BackpropChunk、BackpropMomentum、BackpropWeightDecay、Rprop、Quickprop、SCG（缩放共轭梯度）等。</br>\n            <b>用法</b>\n            <br/>\n            <code> \n            mlp(x, ...)<br/>\n            ## 默认S3方法:<br/>\n            mlp(x, y, size = c(5), maxit = 100,\n              initFunc = \"Randomize_Weights\", initFuncParams = c(-0.3, 0.3),\n              learnFunc = \"Std_Backpropagation\", learnFuncParams = c(0.2, 0),\n              updateFunc = \"Topological_Order\", updateFuncParams = c(0),\n              hiddenActFunc = \"Act_Logistic\", shufflePatterns = TRUE,\n              linOut = FALSE, outputActFunc = if (linOut) \"Act_Identity\" else\n              \"Act_Logistic\", inputsTest = NULL, targetsTest = NULL,\n              pruneFunc = NULL, pruneFuncParams = NULL, ...)\n            </code> <br/>\n            <b>参数</b><br/>\n            <ul>\n            <li>\n            x: 网络的训练输入矩阵\n            </li>\n            <li>\n            ... : 额外的函数参数（当前未使用）\n            </li>\n            <li>\n            y: 相应的目标值\n            </li>\n            <li>\n            size: 隐藏层中的单元数量\n            </li>\n            <li>\n            maxit: 学习的最大迭代次数\n            </li>\n            <li>\n            initFunc: 要使用的初始化函数\n            </li>\n            <li>\n            initFuncParams: 初始化函数的参数\n            </li>\n            <li>\n            learnFunc: 要使用的学习函数\n            </li>\n            <li>\n            learnFuncParams: 学习函数的参数\n            </li>\n            <li>\n            updateFunc: 要使用的更新函数\n            </li>\n            <li>\n            updateFuncParams: 更新函数的参数\n            </li>\n            <li>\n            hiddenActFunc: 所有隐藏单元的激活函数\n            </li>\n            <li>\n            shufflePatterns: 模式是否应被打乱？\n            </li>\n            <li>\n            linOut: 将输出单元的激活函数设置为线性或逻辑（如果给定outputActFunc则忽略）\n            </li>\n            <li>\n            outputActFunc: 所有输出单元的激活函数\n            </li>\n            <li>\n            inputsTest: 用于测试网络的输入矩阵\n            </li>\n            <li>\n            targetsTest: 测试输入的相应目标\n            </li>\n            <li>\n            pruneFunc: 要使用的修剪函数\n            </li>\n            <li>\n            pruneFuncParams: 修剪函数的参数。与其他函数不同，这些必须以命名列表的形式给出。有关进一步说明，请参见修剪演示。\n            </li>\n            </ul>\n            <b>详细信息</b></br>\n            Std_Backpropagation、BackpropBatch等有两个参数，学习率和最大输出差异。学习率通常是0.1到1之间的值。它指定了梯度下降的步长。最大差异定义了输出和目标值之间的差异被视为零误差的程度，并且不进行反向传播。此参数用于防止过度训练。有关所有学习函数的参数的完整列表，请参见SNNS用户手册，第67页。</br>\n            通常不需要更改为初始化和更新函数设置的默认值。</br>\n            <b>值</b><br/>\n            一个rsnns对象。\n            <b>参考文献</b><br/>\n            Rosenblatt, F. (1958), '感知器：信息存储和组织的概率模型', 心理学评论 65(6), 386–408.<br/>\n            Rumelhart, D. E.; Clelland, J. L. M. & Group, P. R. (1986), 并行分布处理：认知微观结构的探索, Mit, 剑桥, MA等.<br/>\n            Zell, A. et al. (1998), 'SNNS斯图加特神经网络模拟器用户手册, 版本4.2', IPVR, 斯图加特大学和图宾根大学WSI.<br/> http://www.ra.cs.uni-tuebingen.de/SNNS/welcome.html<br/>\n            Zell, A. (1994), 神经网络的模拟, Addison-Wesley.（德文）<br/>\n            <b>示例</b><br/>\n            <code> \n            data(iris)<br/>\n            #打乱向量<br/>\n            iris <- iris[sample(1:nrow(iris),length(1:nrow(iris))),1:ncol(iris)]<br/>\n            irisValues <- iris[,1:4]<br/>\n            irisTargets <- decodeClassLabels(iris[,5])<br/>\n            #irisTargets <- decodeClassLabels(iris[,5], valTrue=0.9, valFalse=0.1)<br/>\n            iris <- splitForTrainingAndTest(irisValues, irisTargets, ratio=0.15)<br/>\n            iris <- normTrainingAndTestSet(iris)<br/>\n            model <- mlp(iris$inputsTrain, iris$targetsTrain, size=5, learnFuncParams=c(0.1),\n                          maxit=50, inputsTest=iris$inputsTest, targetsTest=iris$targetsTest)<br/>\n            summary(model)<br/>\n            model<br/>\n            weightMatrix(model)<br/>\n            extractNetInfo(model)<br/>\n            par(mfrow=c(2,2))<br/>\n            plotIterativeError(model)<br/>\n            predictions <- predict(model,iris$inputsTest)<br/>\n            plotRegressionError(predictions[,2], iris$targetsTest[,2])<br/>\n            confusionMatrix(iris$targetsTrain,fitted.values(model))<br/>\n            confusionMatrix(iris$targetsTest,predictions)<br/>\n            plotROC(fitted.values(model)[,2], iris$targetsTrain[,2])<br/>\n            plotROC(predictions[,2], iris$targetsTest[,2])<br/>\n            #使用402040方法的混淆矩阵<br/>\n            confusionMatrix(iris$targetsTrain, encodeClassLabels(fitted.values(model),\n                                                                   method=\"402040\", l=0.4, h=0.6))<br/>\n            </code> <br/>\n            <b>包</b></br>\n            RSNNS;NeuralNetTools</br>\n            <b>帮助</b></br>\n            要详细帮助，请单击此对话框覆盖右上角的R图标或在R语法编辑器中运行以下命令</br>\n            help(mlp, package ='RSNNS')\n\t\t\t"
  }
}
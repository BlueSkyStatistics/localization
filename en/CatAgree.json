{
    "title": "Categorical Agreement",
    "navigation": "Categorical Agreement",
    "ratervars": "Rater Variables:",
    "cilevel": "Confidence Level:",
    "options": "Advanced",
    "categLabels": "Optionally specify all possible ratings separated by , e.g. 1,2,3,4,5 or \"low\",\"medium\",\"high\" ",
    "weightschkbox": "Show category weights",
    "weights": "Select category weights",
    "N": "Finite population size (if any)",
    "help": {
        "title": "Categorical Agreement",
        "r_help": "help(fleiss.kappa.raw, package=irrCAC)",
        "body": "\n<b>Description</b></br>\nComputes percent agreement, Conger's/Cohen's kappa, Fleiss' kappa, Gwet's AC1/AC2, Krippendorff's alpha, and the Brennan-Prediger coefficient among multiple raters (2, 3, +) when the input data represent the raw ratings reported for each subject and each rater.  Unweighted and weighted versions of these statistics are available, with different category weighting methods.</br>\nMissing values are incorported into the chance agreement calculations per Gwet (2014).</br>\nWe also provide the option to display the weightings of the rating categories.</br>\nFor more information, see: </br></br>Gwet, K.L. (2014, ISBN:978-0970806284). “Handbook of Inter-Rater Reliability,” 4th Edition. Advanced Analytics, LLC\n</br></br>Klein, D. (2018) doi:https://doi.org/10.1177/1536867X1801800408. “Implementing a general framework for assessing interrater agreement in Stata,” The Stata Journal Volume 18, Number 4, pp. 871-901.</br></br> \n<b>Usage</b>\n<br/>\n<br/>\n<ul>\n<li>\n<b>Rater Variables:</b>  Variables corresponding to each rater where each column represents one rater and each row one subject. They can be numeric, factor, ordinal, or character variables.</br>\n</li>\n<li>\n<b>Confidence Level:</b>  The confidence level associated with the confidence interval. Its default value is 0.95.</br>\n</li>\n<li>\n<b>Show category weights:</b> shows the numerical weights for the rater categories according to the selected weights.  The selected weighting should correspond to the desired closeness between the categories.\n</li>\n<li>\n<b>Select category weights:</b> A mandatory parameter that is either a string variable or a matrix. The string describes one of the predefined weights and must take one of the values (\"unweighted\",\"quadratic\", \"ordinal\", \"linear\", \"radical\", \"ratio\", \"circular\", \"bipolar\"). </br>\nIf this parameter is a matrix then it must be a square matrix qxq where q is the number of posssible categories where a subject can be classified. If some of the q possible categories are not used, then it is strongly advised to specify the complete list of possible categories. Otherwise, the program may not work.</br>\nNOTE: Specifying a matrix is NOT supported in the syntax. You need to paste the code and edit to specify a matrix.</br>\n</li>\n<li>\n<b>Finite population size (if any):</b> Optional parameter representing the population size (if any). It may be used to perform a finite population correction to the variance. Its default value is infinity.\n</li>\n<li>\n<b>Optionally specify all possible ratings:</b> Optional list used in the case when no rater uses a possible category. If nothing is specified, it's assumed that the oberved categories are the entire category set.\n</li>\n</ul>\n<b>R Package</b></br>\nirrCAC</br>\n<b>Help</b></br>\nThis dialog uses the pa.coeff.raw, conger.kappa.raw, fleiss.kappa.raw, gwet.ac1.raw, krippen.alpha.raw, and bp.coeff.raw functions.\nFor detailed help, see the irrCAC package help at triple dot menu > Help > R Package Help.\n"
    }
}
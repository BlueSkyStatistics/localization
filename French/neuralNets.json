{
  "title": "Formation des réseaux de neurones, utilisant le package neuralnet",
  "navigation": "Réseaux de neurones",
  "label1": "VEUILLEZ CODER EN DUMMY LES VARIABLES FACTORIELLES, VOIR DONNÉES > CALCULER DES VARIABLES DUMMY (GARDER TOUS LES NIVEAUX A.K.A ENCODAGE ONE HOT). ÉCHELLEZ ET CENTREZ LES VARIABLES NUMÉRIQUES, VOIR DONNÉES > STANDARDISER LES VARIABLES",
  "model": "Entrez un nom de modèle",
  "dependentvar": "Variable dépendante",
  "independentvars": "Variable(s) indépendante(s)",
  "seed": "Définir la graine",
  "iter": "Nombre maximum d'étapes pour l'apprentissage",
  "tf": "Algorithme",
  "threshold": "Seuil",
  "label2": "Nombre de couches cachées et de neurones par couche cachée",
  "layers": "Spécifiez le nombre de neurones dans chaque couche, par exemple 1. Pour 5 neurones dans 1 couche, entrez 5 2. Pour 5 neurones dans la couche 1, 6 neurones dans la couche 2, 7 neurones dans la couche 3 entrez 5,6,7",
  "OutActFunc": "Spécifiez une fonction d'activation de sortie",
  "rep": "Répétitions pour l'entraînement du réseau de neurones",
  "label3": "Facteurs de multiplication pour le taux d'apprentissage supérieur et inférieur",
  "minus": "Supérieur (moins)",
  "upper": "Inférieur (plus)",
  "lifesign": "Paramètre indiquant combien imprimer pendant le calcul du réseau de neurones",
  "lifesignstep": "Taille de pas pour imprimer le seuil minimal en mode de vie complet",
  "errfct": "Fonction différentiable utilisée pour le calcul de l'erreur",
  "linearoutput": "La fonction d'activation ne doit pas être appliquée aux neurones de sortie",
  "likelihood": "Vraisemblance",
  "help": {
    "title": "Formation des réseaux de neurones, utilisant le package neuralnet",
    "r_help": "help(neuralnet, package='neuralnet')",
    "body": "\n            <b>NOTE</b></br>\n            Lors de la spécification d'une seule variable dépendante, elle peut être numérique ou factorielle. Si la variable dépendante spécifiée est un facteur, nous codons automatiquement la variable facteur en utilisant l'encodage one-hot avec la fonction decode dans le package RSNNS.</br></br>\n            De plus, si vous utilisez l'encodage one-hot pour coder une variable facteur, vous pouvez spécifier plus d'une variable dépendante dans la boîte de dialogue. Dans ce cas, les variables dépendantes doivent être de type numérique.</br></br>\n            Vous pouvez utiliser \"Données > Calculer des variables dummy\", choisissez le paramètre \"Garder tous les niveaux\" pour obtenir un encodage one-hot.</br></br>\n            Pour les variables dépendantes de type facteur, nous afficherons une matrice de confusion, une ROC et des statistiques de précision du modèle lors de l'évaluation d'un ensemble de données à l'aide du modèle construit. Les prédictions générées sont de type facteur puisque nous prédisons la classe. Celles-ci seront enregistrées dans l'ensemble de données avec les probabilités prédites lors de l'évaluation.</br></br>\n            Lorsqu'il y a des variables dépendantes codées en dummy, nous n'afficherons pas de matrice de confusion, de ROC et de statistiques de précision du modèle lors de l'évaluation d'un ensemble de données à l'aide du modèle construit. Cependant, les prédictions seront enregistrées dans l'ensemble de données lors de l'évaluation de l'ensemble de données. Les prédictions sont les probabilités associées aux variables dépendantes codées en dummy.</br></br>\n            Il est généralement préférable de standardiser les variables indépendantes (elles doivent également être numériques) Voir \"Données > Standardiser les variables.\"</br></br>\n            Si vous avez des variables indépendantes catégorielles, utilisez l'encodage one-hot pour coder les variables facteurs.</br></br>\n            <b>Description</b></br>\n            Entraînez des réseaux de neurones en utilisant la rétropropagation, la rétropropagation résiliente (RPROP) avec (Riedmiller, 1994) ou sans retour en arrière de poids (Riedmiller et Braun, 1993) ou la version modifiée globalement convergente (GRPROP) par Anastasiadis et al. (2005). La fonction permet des réglages flexibles grâce à un choix personnalisé de la fonction d'erreur et de la fonction d'activation. De plus, le calcul des poids généralisés (Intrator O. et Intrator N., 1993) est implémenté.\n            <b>Utilisation</b>\n            <br/>\n            <code> \n            neuralnet(formula, data, hidden = 1, threshold = 0.01,\n              stepmax = 1e+05, rep = 1, startweights = NULL,\n              learningrate.limit = NULL, learningrate.factor = list(minus = 0.5,\n              plus = 1.2), learningrate = NULL, lifesign = \"none\",\n              lifesign.step = 1000, algorithm = \"rprop+\", err.fct = \"sse\",\n              act.fct = \"logistic\", linear.output = TRUE, exclude = NULL,\n              constant.weights = NULL, likelihood = FALSE)\n            </code> <br/>\n            <b>Arguments</b><br/>\n            <ul>\n            <li>\n            formula: une description symbolique du modèle à ajuster.\n            </li>\n            <li>\n            data: un cadre de données contenant les variables spécifiées dans la formule.\n            </li>\n            <li>\n            hidden: un vecteur d'entiers spécifiant le nombre de neurones cachés (sommets) dans chaque couche.\n            </li>\n            <li>\n            threshold: une valeur numérique spécifiant le seuil pour les dérivées partielles de la fonction d'erreur comme critère d'arrêt.\n            </li>\n            <li>\n            stepmax: le nombre maximum d'étapes pour l'entraînement du réseau de neurones. Atteindre ce maximum entraîne l'arrêt du processus d'entraînement du réseau de neurones.\n            </li>\n            <li>\n            rep: le nombre de répétitions pour l'entraînement du réseau de neurones.\n            </li>\n            <li>\n            startweights: un vecteur contenant des valeurs de départ pour les poids. Défini sur NULL pour une initialisation aléatoire.\n            </li>\n            <li>\n            learningrate.limit: un vecteur ou une liste contenant la limite inférieure et supérieure pour le taux d'apprentissage. Utilisé uniquement pour RPROP et GRPROP.</li>\n            <li>\n            learningrate.factor: un vecteur ou une liste contenant les facteurs de multiplication pour le taux d'apprentissage supérieur et inférieur. Utilisé uniquement pour RPROP et GRPROP.\n            </li>\n            <li>\n            learningrate: une valeur numérique spécifiant le taux d'apprentissage utilisé par la rétropropagation traditionnelle. Utilisé uniquement pour la rétropropagation traditionnelle.\n            </li>\n            <li>\n            lifesign: une chaîne spécifiant combien la fonction imprimera pendant le calcul du réseau de neurones. 'none', 'minimal' ou 'full'.\n            </li>\n            <li>\n            lifesign.step: un entier spécifiant la taille de pas pour imprimer le seuil minimal en mode de vie complet.\n            </li>\n            <li>\n            algorithm: une chaîne contenant le type d'algorithme pour calculer le réseau de neurones. Les types suivants sont possibles : 'backprop', 'rprop+', 'rprop-', 'sag', ou 'slr'. 'backprop' fait référence à la rétropropagation, 'rprop+' et 'rprop-' font référence à la rétropropagation résiliente avec et sans retour en arrière de poids, tandis que 'sag' et 'slr' induisent l'utilisation de l'algorithme modifié globalement convergent (grprop). Voir les détails pour plus d'informations.\n            </li>\n            <li>\n            err.fct: une fonction différentiable utilisée pour le calcul de l'erreur. Alternativement, les chaînes 'sse' et 'ce' qui représentent la somme des erreurs au carré et l'entropie croisée peuvent être utilisées.\n            </li>\n            <li>\n            act.fct: une fonction différentiable utilisée pour lisser le résultat du produit croisé des covariables ou des neurones et des poids. De plus, les chaînes 'logistic' et 'tanh' sont possibles pour la fonction logistique et l'hyperbolique tangente.\n            </li>\n            <li>\n            linear.output: logique. Si act.fct ne doit pas être appliqué aux neurones de sortie, définissez la sortie linéaire sur TRUE, sinon sur FALSE.\n            </li>\n            <li>\n            exclude: un vecteur ou une matrice spécifiant les poids qui sont exclus du calcul. S'il est donné sous forme de vecteur, les positions exactes des poids doivent être connues. Une matrice avec n-lignes et 3 colonnes exclura n poids, où la première colonne représente la couche, la deuxième colonne pour le neurone d'entrée et la troisième colonne pour le neurone de sortie du poids.\n            </li>\n            <li>\n            constant.weights: un vecteur spécifiant les valeurs des poids qui sont exclus du processus d'entraînement et traités comme fixes.\n            </li>\n            <li>\n            likelihood: logique. Si la fonction d'erreur est égale à la fonction de vraisemblance négative, les critères d'information AIC et BIC seront calculés. De plus, l'utilisation de confidence.interval est significative.\n            </li>\n            </ul>\n            <b>Détails</b><br/>\n            L'algorithme globalement convergent est basé sur la rétropropagation résiliente sans retour en arrière de poids et modifie en outre un taux d'apprentissage, soit le taux d'apprentissage associé au plus petit gradient absolu (sag) ou le plus petit taux d'apprentissage (slr) lui-même. Les taux d'apprentissage dans l'algorithme grprop sont limités aux limites définies dans learningrate.limit.\n            ​<b>Valeur</b><br/>\n            neuralnet renvoie un objet de classe nn. Un objet de classe nn est une liste contenant au maximum les composants suivants:<br/>\n            call: l'appel correspondant.<br/>\n            response: extrait de l'argument de données.<br/>\n            covariate: les variables extraites de l'argument de données.<br/>\n            model.list: une liste contenant les covariables et les variables de réponse extraites de l'argument de formule.<br/>\n            err.fct: la fonction d'erreur.<br/>\n            act.fct: la fonction d'activation.<br/>\n            data: l'argument de données.<br/>\n            net.result: une liste contenant le résultat global du réseau de neurones pour chaque répétition.<br/>\n            weights: une liste contenant les poids ajustés du réseau de neurones pour chaque répétition.<br/>\n            generalized.weights: une liste contenant les poids généralisés du réseau de neurones pour chaque répétition.<br/>\n            result.matrix: une matrice contenant le seuil atteint, les étapes nécessaires, l'erreur, AIC et BIC (si calculé) et les poids pour chaque répétition. Chaque colonne représente une répétition.<br/>\n            startweights: une liste contenant les poids de départ du réseau de neurones pour chaque répétition.<br/>\n            ​<b>Exemples</b><br/>\n            <code> \n            ​library(neuralnet)\n            ​# Classification binaire\n            nn <- neuralnet(Species == \"setosa\" ~ Petal.Length + Petal.Width, iris, linear.output = FALSE)\n            ## Non exécuté : print(nn)\n            ## Non exécuté : plot(nn)\n            # Classification multiclass\n            nn <- neuralnet(Species ~ Petal.Length + Petal.Width, iris, linear.output = FALSE)\n            ## Non exécuté : print(nn)\n            ## Non exécuté : plot(nn)\n            # Fonction d'activation personnalisée\n            softplus <- function(x) log(1 + exp(x))\n            nn <- neuralnet((Species == \"setosa\") ~ Petal.Length + Petal.Width, iris, \n                            linear.output = FALSE, hidden = c(3, 2), act.fct = softplus)\n            ## Non exécuté : print(nn)\n            ## Non exécuté : plot(nn)\n            </code> <br/>\n            <b>Package</b></br>\n            neuralnet;NeuralNetTools</br>\n            <b>Aide</b></br>\n            Pour une aide détaillée, cliquez sur l'icône R en haut à droite de cette boîte de dialogue ou exécutez la commande suivante dans l'éditeur de syntaxe R</br>\n            help(neuralnet, package='neuralnet')\n\t\t\t"
  }
}
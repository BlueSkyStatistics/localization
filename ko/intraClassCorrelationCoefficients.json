{
  "title": "군내 상관 계수",
  "navigation": "군내 상관 계수",
  "ratervars": "평가자 변수:",
  "cilevel": "신뢰 수준:",
  "modeldetails": "모델 세부정보",
  "help": {
    "title": "군내 상관 계수",
    "r_help": "help(ICC, package=psych)",
    "body": "\n<b>설명</b></br>\n이것은 Shrout와 Fleiss(1979, Psychological Bulletin)의 6개의 군내 상관 계수(ICC)를 계산합니다. 추정은 제한된 최대 우도법을 사용한 선형 혼합 효과 모델을 사용하여 수행되므로 결측 데이터를 처리할 수 있습니다.</br>\nShrout와 Fleiss는 n개의 대상에 대해 k명의 평가자가 수행한 평가의 신뢰성의 여섯 가지 경우를 고려합니다.</br>\nICC1: 각 대상은 서로 다른 k명의 심사자 집단에 의해 평가되며, 심사자는 무작위로 선택됩니다. 이것은 평가의 절대적 합의의 척도입니다.</br>\nICC2: 무작위 샘플의 k명의 심사자가 각 대상을 평가합니다.</br>\nICC3: 고정된 k명의 심사자가 각 대상을 평가합니다. 이는 더 큰 심사자 집단에 대한 일반화가 없습니다.</br>\n그런 다음 이러한 각 경우에 대해 단일 평가 또는 k개의 평가의 평균에 대한 신뢰성을 추정해야 합니까? ICC1은 평가자 간의 평균 차이에 민감하며 절대적 합의의 척도입니다. ICC2와 ICC3는 평가자 간의 평균 차이를 제거하지만, 주제에 대한 평가자의 상호작용에 민감합니다. ICC2와 ICC3의 차이는 평가자가 고정 효과로 간주되는지 무작위 효과로 간주되는지 여부입니다. ICC1k, ICC2k 및 ICC3K는 k명의 평가자의 평균을 반영합니다.</br>\n평가자 변수: 각 평가자에 해당하는 변수. 이들은 숫자 변수여야 합니다.</br>\n신뢰 구간 수준: ICC의 신뢰 구간에 대한 원하는 수준</br>\n모델 세부정보: 기본 혼합 효과 선형 모델의 세부정보 표시</br>\n<b>패키지</b></br>\npsych</br>\n<b>도움말</b></br>\n자세한 도움말은 이 대화 상자의 오른쪽 상단에 있는 R 아이콘을 클릭하거나 다음 명령어 help(ICC, package=psych)를 실행하여 R 코드 청크를 생성하여 +를 클릭하여 출력 창에서 실행하십시오.\n\t\t\t"
  }
}
{
  "title": "Acuerdo Categórico",
  "navigation": "Acuerdo Categórico",
  "ratervars": "Variables del Evaluador:",
  "cilevel": "Nivel de Confianza:",
  "options": "Avanzado",
  "categLabels": "Especifique opcionalmente todas las calificaciones posibles separadas por , por ejemplo 1,2,3,4,5 o \"bajo\",\"medio\",\"alto\" ",
  "weightschkbox": "Mostrar pesos de categoría",
  "weights": "Seleccionar pesos de categoría",
  "N": "Tamaño de población finita (si lo hay)",
  "help": {
    "title": "Acuerdo Categórico",
    "r_help": "ayuda(fleiss.kappa.raw, paquete=irrCAC)",
    "body": "\n<b>Descripción</b></br>\nCalcula el porcentaje de acuerdo, el kappa de Conger/Cohen, el kappa de Fleiss, AC1/AC2 de Gwet, el alfa de Krippendorff y el coeficiente de Brennan-Prediger entre múltiples evaluadores (2, 3, +) cuando los datos de entrada representan las calificaciones brutas reportadas para cada sujeto y cada evaluador. Se encuentran disponibles versiones no ponderadas y ponderadas de estas estadísticas, con diferentes métodos de ponderación de categorías.</br>\nLos valores faltantes se incorporan en los cálculos de acuerdo aleatorio según Gwet (2014).</br>\nTambién ofrecemos la opción de mostrar los pesos de las categorías de calificación.</br>\nPara más información, consulte: </br></br>Gwet, K.L. (2014, ISBN:978-0970806284). “Manual de Fiabilidad Inter-Rater,” 4ª Edición. Advanced Analytics, LLC\n</br></br>Klein, D. (2018) doi:https://doi.org/10.1177/1536867X1801800408. “Implementación de un marco general para evaluar el acuerdo inter-evaluador en Stata,” The Stata Journal Volumen 18, Número 4, pp. 871-901.</br></br> \n<b>Uso</b>\n<br/>\n<br/>\n<ul>\n<li>\n<b>Variables del Evaluador:</b>  Variables que corresponden a cada evaluador donde cada columna representa un evaluador y cada fila un sujeto. Pueden ser variables numéricas, de factor, ordinales o de carácter.</br>\n</li>\n<li>\n<b>Nivel de Confianza:</b>  El nivel de confianza asociado con el intervalo de confianza. Su valor predeterminado es 0.95.</br>\n</li>\n<li>\n<b>Mostrar pesos de categoría:</b> muestra los pesos numéricos para las categorías de evaluadores según los pesos seleccionados. El peso seleccionado debe corresponder a la cercanía deseada entre las categorías.\n</li>\n<li>\n<b>Seleccionar pesos de categoría:</b> Un parámetro obligatorio que es una variable de cadena o una matriz. La cadena describe uno de los pesos predefinidos y debe tomar uno de los valores (\"no ponderado\",\"cuadrático\", \"ordinal\", \"lineal\", \"radical\", \"razón\", \"circular\", \"bipolar\"). </br>\nSi este parámetro es una matriz, debe ser una matriz cuadrada qxq donde q es el número de categorías posibles en las que un sujeto puede ser clasificado. Si algunas de las q categorías posibles no se utilizan, se recomienda encarecidamente especificar la lista completa de categorías posibles. De lo contrario, el programa puede no funcionar.</br>\nNOTA: Especificar una matriz NO es compatible en la sintaxis. Debe pegar el código y editar para especificar una matriz.</br>\n</li>\n<li>\n<b>Tamaño de población finita (si lo hay):</b> Parámetro opcional que representa el tamaño de la población (si lo hay). Puede ser utilizado para realizar una corrección de población finita a la varianza. Su valor predeterminado es infinito.\n</li>\n<li>\n<b>Especifique opcionalmente todas las calificaciones posibles:</b> Lista opcional utilizada en el caso de que ningún evaluador use una categoría posible. Si no se especifica nada, se asume que las categorías observadas son el conjunto completo de categorías.\n</li>\n</ul>\n<b>Paquete R</b></br>\nirrCAC</br>\n<b>Ayuda</b></br>\nEste cuadro de diálogo utiliza las funciones pa.coeff.raw, conger.kappa.raw, fleiss.kappa.raw, gwet.ac1.raw, krippen.alpha.raw y bp.coeff.raw.\nPara ayuda detallada, consulte la ayuda del paquete irrCAC en el menú de tres puntos > Ayuda > Ayuda del paquete R.\n"
  }
}
{
  "title": "البرسيفترون متعدد الطبقات، باستخدام حزمة RSNNS",
  "navigation": "البرسيفترون متعدد الطبقات",
  "label1": "يرجى ترميز المتغيرات الوهمية، انظر البيانات > حساب المتغيرات الوهمية (احتفظ بجميع المستويات أي الترميز الأحادي). قم بتقييس وتوسيع المتغيرات العددية، انظر البيانات > قياس المتغيرات",
  "model": "أدخل اسم النموذج",
  "dependentvar": "المتغير التابع",
  "independentvars": "المتغير (المتغيرات) المستقلة",
  "seed": "تعيين البذور",
  "iter": "الحد الأقصى من التكرارات للتعلم",
  "tf": "وظيفة التعلم",
  "label2": "عدد الطبقات المخفية وعدد الخلايا العصبية في كل طبقة مخفية",
  "layers": "حدد عدد الخلايا العصبية في كل طبقة، على سبيل المثال 1. لعدد 5 خلايا عصبية في طبقة واحدة، أدخل 5 2. لعدد 5 خلايا عصبية في الطبقة 1، و6 خلايا عصبية في الطبقة 2، و7 خلايا عصبية في الطبقة 3 أدخل 5،6،7",
  "learnfuncparams": "معلمات وظيفة التعلم",
  "help": {
    "title": "البرسيفترون متعدد الطبقات، باستخدام حزمة RSNNS",
    "r_help": "help(mlp, package ='RSNNS')",
    "body": "\n            <b>ملاحظة</b></br>\n            عند تحديد متغير تابع واحد، يمكن أن يكون عدديًا أو عاملاً. إذا كان المتغير التابع المحدد عاملًا، فإننا نقوم تلقائيًا بترميز المتغير العامل باستخدام الترميز الأحادي باستخدام وظيفة decode في حزمة RSNNS.</br></br>\n            بالإضافة إلى ذلك، إذا كنت تستخدم الترميز الأحادي لترميز متغير عامل، يمكنك تحديد أكثر من متغير تابع في الحوار. في هذه الحالة، يجب أن تكون المتغيرات التابعة من النوع العددي.</br></br>\n            يمكنك استخدام \"البيانات > حساب المتغيرات الوهمية\"، اختر إعداد \"احتفظ بجميع المستويات\" للحصول على الترميز الأحادي.</br></br>\n            بالنسبة للمتغيرات التابعة من النوع العامل، سنعرض مصفوفة الارتباك، وROC وإحصائيات دقة النموذج عند تقييم مجموعة بيانات باستخدام النموذج المبني. التوقعات الناتجة هي من النوع العامل حيث نتوقع الفئة. سيتم حفظ هذه في مجموعة البيانات جنبًا إلى جنب مع الاحتمالات المتوقعة عند التقييم.</br></br>\n            عندما تكون هناك متغيرات تابعة مشفرة وهميًا، لن نعرض مصفوفة الارتباك، وROC وإحصائيات دقة النموذج عند تقييم مجموعة بيانات باستخدام النموذج المبني. ومع ذلك، سيتم حفظ التوقعات في مجموعة البيانات عند تقييم مجموعة البيانات. التوقعات هي الاحتمالات المرتبطة بالمتغيرات التابعة المشفرة وهميًا.</br></br>\n            من الأفضل عادةً قياس المتغيرات المستقلة (يجب أن تكون عددية أيضًا) انظر \"البيانات > قياس المتغيرات\".</br></br>\n            إذا كان لديك متغيرات مستقلة فئوية، استخدم الترميز الأحادي لترميز المتغيرات العاملية.</br></br>\n            <b>الوصف</b></br>\n            هذه الوظيفة تنشئ برسيترون متعدد الطبقات (MLP) وتدربه. تعتبر MLPs شبكات متصلة بالكامل، وربما هي أكثر بنية شبكة شائعة الاستخدام. يتم التدريب عادةً بواسطة تراجع الخطأ أو إجراء ذي صلة.</br>\n            هناك العديد من وظائف التعلم المختلفة الموجودة في SNNS التي يمكن استخدامها مع هذه الوظيفة، مثل Std_Backpropagation، BackpropBatch، BackpropChunk، BackpropMomentum، BackpropWeightDecay، Rprop، Quickprop، SCG (تدرج مقنن)، ...</br>\n            <b>الاستخدام</b>\n            <br/>\n            <code> \n            mlp(x, ...)<br/>\n            ## الطريقة الافتراضية S3:<br/>\n            mlp(x, y, size = c(5), maxit = 100,\n              initFunc = \"Randomize_Weights\", initFuncParams = c(-0.3, 0.3),\n              learnFunc = \"Std_Backpropagation\", learnFuncParams = c(0.2, 0),\n              updateFunc = \"Topological_Order\", updateFuncParams = c(0),\n              hiddenActFunc = \"Act_Logistic\", shufflePatterns = TRUE,\n              linOut = FALSE, outputActFunc = if (linOut) \"Act_Identity\" else\n              \"Act_Logistic\", inputsTest = NULL, targetsTest = NULL,\n              pruneFunc = NULL, pruneFuncParams = NULL, ...)\n            </code> <br/>\n            <b>المعلمات</b><br/>\n            <ul>\n            <li>\n            x: مصفوفة تحتوي على المدخلات التدريبية للشبكة\n            </li>\n            <li>\n            ... : معلمات إضافية للوظيفة (حاليًا غير مستخدمة)\n            </li>\n            <li>\n            y: القيم المستهدفة المقابلة\n            </li>\n            <li>\n            size: عدد الوحدات في الطبقة (الطبقات) المخفية\n            </li>\n            <li>\n            maxit: الحد الأقصى من التكرارات للتعلم\n            </li>\n            <li>\n            initFunc: وظيفة التهيئة للاستخدام\n            </li>\n            <li>\n            initFuncParams: المعلمات لوظيفة التهيئة\n            </li>\n            <li>\n            learnFunc: وظيفة التعلم للاستخدام\n            </li>\n            <li>\n            learnFuncParams: المعلمات لوظيفة التعلم\n            </li>\n            <li>\n            updateFunc: وظيفة التحديث للاستخدام\n            </li>\n            <li>\n            updateFuncParams: المعلمات لوظيفة التحديث\n            </li>\n            <li>\n            hiddenActFunc: وظيفة التنشيط لجميع الوحدات المخفية\n            </li>\n            <li>\n            shufflePatterns: هل يجب خلط الأنماط؟\n            </li>\n            <li>\n            linOut: يحدد وظيفة التنشيط لوحدات الإخراج لتكون خطية أو لوجستية (يتم تجاهلها إذا تم إعطاء outputActFunc)\n            </li>\n            <li>\n            outputActFunc: وظيفة التنشيط لجميع وحدات الإخراج\n            </li>\n            <li>\n            inputsTest: مصفوفة تحتوي على المدخلات لاختبار الشبكة\n            </li>\n            <li>\n            targetsTest: القيم المستهدفة المقابلة لمدخلات الاختبار\n            </li>\n            <li>\n            pruneFunc: وظيفة التقليم للاستخدام\n            </li>\n            <li>\n            pruneFuncParams: المعلمات لوظيفة التقليم. على عكس الوظائف الأخرى، يجب إعطاؤها في قائمة مسماة. انظر العروض التوضيحية للتقليم لمزيد من الشرح.\n            </li>\n            </ul>\n            <b>التفاصيل</b></br>\n            Std_Backpropagation، BackpropBatch، على سبيل المثال، لديها معلمتين، معدل التعلم والفرق الأقصى للإخراج. عادةً ما يكون معدل التعلم قيمة بين 0.1 و1. يحدد عرض خطوة تراجع التدرج. الفرق الأقصى يحدد، كم من الفرق بين القيمة الناتجة والقيمة المستهدفة يتم اعتباره خطأ صفر، وليس متراجعًا. تُستخدم هذه المعلمة لمنع الإفراط في التدريب. للحصول على قائمة كاملة بمعلمات جميع وظائف التعلم، انظر دليل مستخدم SNNS، ص. 67.</br>\n            عادةً لا تحتاج القيم الافتراضية التي تم تعيينها لوظائف التهيئة والتحديث إلى تغيير.</br>\n            <b>القيمة</b><br/>\n            كائن rsnns.\n            <b>المراجع</b><br/>\n            روزنبلات، ف. (1958)، 'البرسيفترون: نموذج احتمالي لتخزين المعلومات وتنظيمها في الدماغ'، مراجعة نفسية 65(6)، 386–408.<br/>\n            روملهارت، د. إ.; كليفلاند، ج. ل. م. & مجموعة، ب. ر. (1986)، المعالجة الموزعة بالتوازي: استكشافات في البنية الدقيقة للإدراك، ميت، كامبريدج، ماساتشوستس وما إلى ذلك.<br/>\n            زيل، أ. وآخرون. (1998)، 'دليل مستخدم محاكي الشبكات العصبية SNNS، الإصدار 4.2'، IPVR، جامعة شتوتغارت وWSI، جامعة توبنغن.<br/> http://www.ra.cs.uni-tuebingen.de/SNNS/welcome.html<br/>\n            زيل، أ. (1994)، محاكاة الشبكات العصبية، أديون-ويلي. (بالألمانية)<br/>\n            <b>أمثلة</b><br/>\n            <code> \n            data(iris)<br/>\n            #خلط المتجه<br/>\n            iris <- iris[sample(1:nrow(iris),length(1:nrow(iris))),1:ncol(iris)]<br/>\n            irisValues <- iris[,1:4]<br/>\n            irisTargets <- decodeClassLabels(iris[,5])<br/>\n            #irisTargets <- decodeClassLabels(iris[,5], valTrue=0.9, valFalse=0.1)<br/>\n            iris <- splitForTrainingAndTest(irisValues, irisTargets, ratio=0.15)<br/>\n            iris <- normTrainingAndTestSet(iris)<br/>\n            model <- mlp(iris$inputsTrain, iris$targetsTrain, size=5, learnFuncParams=c(0.1),\n                          maxit=50, inputsTest=iris$inputsTest, targetsTest=iris$targetsTest)<br/>\n            summary(model)<br/>\n            model<br/>\n            weightMatrix(model)<br/>\n            extractNetInfo(model)<br/>\n            par(mfrow=c(2,2))<br/>\n            plotIterativeError(model)<br/>\n            predictions <- predict(model,iris$inputsTest)<br/>\n            plotRegressionError(predictions[,2], iris$targetsTest[,2])<br/>\n            confusionMatrix(iris$targetsTrain,fitted.values(model))<br/>\n            confusionMatrix(iris$targetsTest,predictions)<br/>\n            plotROC(fitted.values(model)[,2], iris$targetsTrain[,2])<br/>\n            plotROC(predictions[,2], iris$targetsTest[,2])<br/>\n            #مصفوفة الارتباك باستخدام طريقة 402040<br/>\n            confusionMatrix(iris$targetsTrain, encodeClassLabels(fitted.values(model),\n                                                                   method=\"402040\", l=0.4, h=0.6))<br/>\n            </code> <br/>\n            <b>الحزمة</b></br>\n            RSNNS; أدوات الشبكات العصبية</br>\n            <b>المساعدة</b></br>\n            للحصول على مساعدة مفصلة، انقر على أيقونة R في الزاوية العلوية اليمنى من هذه النافذة الحوارية أو قم بتشغيل الأمر التالي في محرر بناء الجملة R</br>\n            help(mlp, package ='RSNNS')\n\t\t\t"
  }
}
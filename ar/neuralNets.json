{
  "title": "تدريب الشبكات العصبية باستخدام حزمة neuralnet",
  "navigation": "الشبكات العصبية",
  "label1": "يرجى ترميز المتغيرات الوهمية، انظر البيانات > حساب المتغيرات الوهمية (احتفظ بجميع المستويات أي الترميز الأحادي). قم بتقييس وتوسيع المتغيرات العددية، انظر البيانات > قياس المتغيرات",
  "model": "أدخل اسم النموذج",
  "dependentvar": "المتغير التابع",
  "independentvars": "المتغير (المتغيرات) المستقلة",
  "seed": "تعيين البذور",
  "iter": "الحد الأقصى من الخطوات للتعلم",
  "tf": "الخوارزمية",
  "threshold": "العتبة",
  "label2": "عدد الطبقات المخفية وعدد الخلايا العصبية في كل طبقة مخفية",
  "layers": "حدد عدد الخلايا العصبية في كل طبقة، على سبيل المثال 1. لعدد 5 خلايا عصبية في طبقة واحدة، أدخل 5 2. لعدد 5 خلايا عصبية في الطبقة 1، و6 خلايا عصبية في الطبقة 2، و7 خلايا عصبية في الطبقة 3 أدخل 5،6،7",
  "OutActFunc": "حدد دالة تنشيط الإخراج",
  "rep": "عدد التكرارات لتدريب الشبكة العصبية",
  "label3": "عوامل الضرب لمعدل التعلم العلوي والسفلي",
  "minus": "علوي (ناقص)",
  "upper": "سفلي (زائد)",
  "lifesign": "إعداد مقدار الطباعة أثناء حساب الشبكة العصبية",
  "lifesignstep": "حجم الخطوة لطباعة الحد الأدنى في وضع الطباعة الكامل",
  "errfct": "دالة قابلة للاشتقاق تستخدم لحساب الخطأ",
  "linearoutput": "لا ينبغي تطبيق دالة التنشيط على خلايا الإخراج العصبية",
  "likelihood": "الاحتمالية",
  "advanced_lbl": "متقدم",
  "help": {
    "title": "تدريب الشبكات العصبية باستخدام حزمة neuralnet",
    "r_help": "help(neuralnet, package='neuralnet')",
    "body": "\n            <b>ملاحظة</b></br>\n            عند تحديد متغير تابع واحد، يمكن أن يكون عدديًا أو عاملًا. إذا كان المتغير التابع المحدد عاملًا، نقوم تلقائيًا بترميز المتغير الوهمي باستخدام الترميز الأحادي باستخدام دالة decode في حزمة RSNNS.</br></br>\n            بالإضافة إلى ذلك، إذا كنت تستخدم الترميز الأحادي لترميز متغير عامل، يمكنك تحديد أكثر من متغير تابع في الحوار. في هذه الحالة، يجب أن تكون المتغيرات التابعة من النوع العددي.</br></br>\n            يمكنك استخدام \"البيانات > حساب المتغيرات الوهمية\"، اختر إعداد \"احتفظ بجميع المستويات\" للحصول على الترميز الأحادي.</br></br>\n            بالنسبة للمتغيرات التابعة من النوع العامل، سنعرض مصفوفة الارتباك، ROC وإحصائيات دقة النموذج عند تقييم مجموعة بيانات باستخدام النموذج المبني. التوقعات الناتجة هي من النوع العامل حيث نتوقع الفئة. سيتم حفظ هذه في مجموعة البيانات مع الاحتمالات المتوقعة عند التقييم.</br></br>\n            عندما تكون هناك متغيرات تابعة مشفرة وهميًا، لن نعرض مصفوفة الارتباك، ROC وإحصائيات دقة النموذج عند تقييم مجموعة بيانات باستخدام النموذج المبني. ومع ذلك، سيتم حفظ التوقعات في مجموعة البيانات عند تقييم مجموعة البيانات. التوقعات هي الاحتمالات المرتبطة بالمتغيرات التابعة المشفرة وهميًا.</br></br>\n            من الأفضل عادةً قياس المتغيرات المستقلة (يجب أن تكون عددية أيضًا) انظر \"البيانات > قياس المتغيرات\".</br></br>\n            إذا كان لديك متغيرات مستقلة فئوية، استخدم الترميز الأحادي لترميز المتغيرات العاملية.</br></br>\n            <b>الوصف</b></br>\n            تدريب الشبكات العصبية باستخدام الانتشار العكسي، الانتشار العكسي المرن (RPROP) مع (Riedmiller، 1994) أو بدون تتبع الوزن (Riedmiller و Braun، 1993) أو النسخة المعدلة المتقاربة عالميًا (GRPROP) بواسطة Anastasiadis وآخرون (2005). تتيح الدالة إعدادات مرنة من خلال اختيار مخصص لدالة الخطأ ودالة التنشيط. علاوة على ذلك، يتم تنفيذ حساب الأوزان العامة (Intrator O. و Intrator N.، 1993).\n            <b>الاستخدام</b>\n            <br/>\n            <code> \n            neuralnet(formula, data, hidden = 1, threshold = 0.01,\n              stepmax = 1e+05, rep = 1, startweights = NULL,\n              learningrate.limit = NULL, learningrate.factor = list(minus = 0.5,\n              plus = 1.2), learningrate = NULL, lifesign = \"none\",\n              lifesign.step = 1000, algorithm = \"rprop+\", err.fct = \"sse\",\n              act.fct = \"logistic\", linear.output = TRUE, exclude = NULL,\n              constant.weights = NULL, likelihood = FALSE)\n            </code> <br/>\n            <b>المعلمات</b><br/>\n            <ul>\n            <li>\n            formula: وصف رمزي للنموذج الذي سيتم ملؤه.\n            </li>\n            <li>\n            data: إطار بيانات يحتوي على المتغيرات المحددة في الصيغة.\n            </li>\n            <li>\n            hidden: متجه من الأعداد الصحيحة يحدد عدد الخلايا العصبية المخفية (الرؤوس) في كل طبقة.\n            </li>\n            <li>\n            threshold: قيمة عددية تحدد العتبة للمشتقات الجزئية لدالة الخطأ كمعيار للتوقف.\n            </li>\n            <li>\n            stepmax: الحد الأقصى من الخطوات لتدريب الشبكة العصبية. يؤدي الوصول إلى هذا الحد الأقصى إلى توقف عملية تدريب الشبكة العصبية.\n            </li>\n            <li>\n            rep: عدد التكرارات لتدريب الشبكة العصبية.\n            </li>\n            <li>\n            startweights: متجه يحتوي على قيم البداية للأوزان. تعيين إلى NULL للت initialization العشوائي.\n            </li>\n            <li>\n            learningrate.limit: متجه أو قائمة تحتوي على الحد الأدنى والأقصى لمعدل التعلم. يستخدم فقط لـ RPROP و GRPROP.</li>\n            <li>\n            learningrate.factor: متجه أو قائمة تحتوي على عوامل الضرب لمعدل التعلم العلوي والسفلي. يستخدم فقط لـ RPROP و GRPROP.\n            </li>\n            <li>\n            learningrate: قيمة عددية تحدد معدل التعلم المستخدم من قبل الانتشار العكسي التقليدي. يستخدم فقط للانتشار العكسي التقليدي.\n            </li>\n            <li>\n            lifesign: سلسلة تحدد مقدار ما ستطبعه الدالة أثناء حساب الشبكة العصبية. 'none'، 'minimal' أو 'full'.\n            </li>\n            <li>\n            lifesign.step: عدد صحيح يحدد حجم الخطوة لطباعة الحد الأدنى في وضع الطباعة الكامل.\n            </li>\n            <li>\n            algorithm: سلسلة تحتوي على نوع الخوارزمية لحساب الشبكة العصبية. الأنواع التالية ممكنة: 'backprop'، 'rprop+'، 'rprop-'، 'sag'، أو 'slr'. تشير 'backprop' إلى الانتشار العكسي، بينما تشير 'rprop+' و 'rprop-' إلى الانتشار العكسي المرن مع وبدون تتبع الوزن، بينما تحفز 'sag' و 'slr' استخدام الخوارزمية المعدلة المتقاربة عالميًا (grprop). انظر التفاصيل لمزيد من المعلومات.\n            </li>\n            <li>\n            err.fct: دالة قابلة للاشتقاق تستخدم لحساب الخطأ. بدلاً من ذلك، يمكن استخدام السلاسل 'sse' و 'ce' التي تمثل مجموع الأخطاء المربعة والانتروبيا المتقاطعة.\n            </li>\n            <li>\n            act.fct: دالة قابلة للاشتقاق تستخدم لتنعيم نتيجة حاصل الضرب المتقاطع للمتغيرات أو الخلايا العصبية والأوزان. بالإضافة إلى ذلك، يمكن استخدام السلاسل 'logistic' و 'tanh' للدالة اللوجستية والزاوية المماسية.\n            </li>\n            <li>\n            linear.output: منطقي. إذا لم يكن ينبغي تطبيق act.fct على خلايا الإخراج العصبية، قم بتعيين الإخراج الخطي إلى TRUE، وإلا إلى FALSE.\n            </li>\n            <li>\n            exclude: متجه أو مصفوفة تحدد الأوزان التي يتم استبعادها من الحساب. إذا تم إعطاؤها كمتجه، يجب معرفة المواقع الدقيقة للأوزان. ستستبعد مصفوفة تحتوي على n صفوف و 3 أعمدة n أوزان، حيث تمثل العمود الأول الطبقة، والعمود الثاني الخلية العصبية المدخلة، والعمود الثالث الخلية العصبية المخرجة للوزن.\n            </li>\n            <li>\n            constant.weights: متجه يحدد قيم الأوزان التي يتم استبعادها من عملية التدريب وتعتبر ثابتة.\n            </li>\n            <li>\n            likelihood: منطقي. إذا كانت دالة الخطأ تساوي دالة الاحتمالية السلبية، فسيتم حساب معايير المعلومات AIC و BIC. علاوة على ذلك، فإن استخدام confidence.interval له معنى.\n            </li>\n            </ul>\n            <b>التفاصيل</b><br/>\n            تعتمد الخوارزمية المتقاربة عالميًا على الانتشار العكسي المرن بدون تتبع الوزن وتعدل أيضًا معدل تعلم واحد، إما معدل التعلم المرتبط بأقل تدرج مطلق (sag) أو أقل معدل تعلم (slr) نفسه. يتم تحديد معدلات التعلم في خوارزمية grprop ضمن الحدود المحددة في learningrate.limit.\n            ​<b>القيمة</b><br/>\n            تعيد neuralnet كائنًا من فئة nn. كائن من فئة nn هو قائمة تحتوي على ما يصل إلى المكونات التالية:<br/>\n            call: الاستدعاء المطابق.<br/>\n            response: مستخرج من وسيط البيانات.<br/>\n            covariate: المتغيرات المستخرجة من وسيط البيانات.<br/>\n            model.list: قائمة تحتوي على المتغيرات المستقلة والمتغيرات التابعة المستخرجة من وسيط الصيغة.<br/>\n            err.fct: دالة الخطأ.<br/>\n            act.fct: دالة التنشيط.<br/>\n            data: وسيط البيانات.<br/>\n            net.result: قائمة تحتوي على النتيجة العامة للشبكة العصبية لكل تكرار.<br/>\n            weights: قائمة تحتوي على الأوزان الملائمة للشبكة العصبية لكل تكرار.<br/>\n            generalized.weights: قائمة تحتوي على الأوزان العامة للشبكة العصبية لكل تكرار.<br/>\n            result.matrix: مصفوفة تحتوي على العتبة المحققة، الخطوات المطلوبة، الخطأ، AIC و BIC (إذا تم حسابها) والأوزان لكل تكرار. تمثل كل عمود تكرار واحد.<br/>\n            startweights: قائمة تحتوي على الأوزان الابتدائية للشبكة العصبية لكل تكرار.<br/>\n            ​<b>أمثلة</b><br/>\n            <code> \n            ​library(neuralnet)\n            ​# تصنيف ثنائي\n            nn <- neuralnet(Species == \"setosa\" ~ Petal.Length + Petal.Width, iris, linear.output = FALSE)\n            ## لم يتم تشغيله: print(nn)\n            ## لم يتم تشغيله: plot(nn)\n            # تصنيف متعدد الفئات\n            nn <- neuralnet(Species ~ Petal.Length + Petal.Width, iris, linear.output = FALSE)\n            ## لم يتم تشغيله: print(nn)\n            ## لم يتم تشغيله: plot(nn)\n            # دالة تنشيط مخصصة\n            softplus <- function(x) log(1 + exp(x))\n            nn <- neuralnet((Species == \"setosa\") ~ Petal.Length + Petal.Width, iris, \n                            linear.output = FALSE, hidden = c(3, 2), act.fct = softplus)\n            ## لم يتم تشغيله: print(nn)\n            ## لم يتم تشغيله: plot(nn)\n            </code> <br/>\n            <b>الحزمة</b></br>\n            neuralnet;NeuralNetTools</br>\n            <b>المساعدة</b></br>\n            للحصول على مساعدة مفصلة، انقر على أيقونة R في الزاوية العلوية اليمنى من هذه النافذة المنبثقة أو قم بتشغيل الأمر التالي في محرر بناء الجملة R</br>\n            help(neuralnet, package='neuralnet')\n\t\t\t"
  }
}
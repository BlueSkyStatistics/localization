{
  "title": "Perceptrón multicapa, utilizando el paquete RSNNS",
  "navigation": "Perceptrón multicapa",
  "label1": "POR FAVOR CODIFIQUE VARIABLES FACTOR DUMMY, VEA DATOS > CALCULAR VARIABLES DUMMY (MANTENER TODOS LOS NIVELES A.K.A CODIFICACIÓN ONE HOT). ESCALAR Y CENTRAR VARIABLES NUMÉRICAS, VEA DATOS > ESTANDARIZAR VARIABLES",
  "model": "Ingrese un nombre de modelo",
  "dependentvar": "Variable dependiente",
  "independentvars": "Variable(s) independiente(s)",
  "seed": "Establecer semilla",
  "iter": "Máximas iteraciones para aprender",
  "tf": "Función de aprendizaje",
  "label2": "Número de capas ocultas y neuronas por capa oculta",
  "layers": "Especifique el número de neuronas en cada capa, por ejemplo 1. Para 5 neuronas en 1 capa, ingrese 5 2. Para 5 neuronas en la capa 1, 6 neuronas en la capa 2, 7 neuronas en la capa 3 ingrese 5,6,7",
  "learnfuncparams": "Parámetros de la función de aprendizaje",
  "help": {
    "title": "Perceptrón multicapa, utilizando el paquete RSNNS",
    "r_help": "help(mlp, package ='RSNNS')",
    "body": "\n            <b>NOTA</b></br>\n            Cuando especifica una sola variable dependiente, puede ser numérica o factor. Si la variable dependiente especificada es un factor, codificamos automáticamente la variable factor utilizando codificación one-hot mediante la función decode en el paquete RSNNS.</br></br>\n            Además, si está utilizando codificación one-hot para codificar una variable factor, puede especificar más de una variable dependiente en el diálogo. En este caso, las variables dependientes deben ser de tipo numérico.</br></br>\n            Puede usar \"Datos > Calcular variables dummy\", elija la configuración “Mantener todos los niveles” para obtener codificación one-hot.</br></br>\n            Para variables dependientes de tipo factor, mostraremos una matriz de confusión, ROC y estadísticas de precisión del modelo al puntuar un conjunto de datos utilizando el modelo construido. Las predicciones generadas son de tipo factor ya que predecimos la clase. Estas se guardarán en el conjunto de datos junto con las probabilidades predichas al puntuar.</br></br>\n            Cuando hay variables dependientes codificadas como dummy, no mostraremos una matriz de confusión, ROC y estadísticas de precisión del modelo al puntuar un conjunto de datos utilizando el modelo construido. Sin embargo, las predicciones se guardarán en el conjunto de datos al puntuar el conjunto de datos. Las predicciones son las probabilidades asociadas con las variables dependientes codificadas como dummy.</br></br>\n            Generalmente es mejor estandarizar las variables independientes (también deben ser numéricas) Vea “Datos > Estandarizar Variables.”</br></br>\n            Si tiene variables independientes categóricas, use codificación one-hot para codificar las variables factor.</br></br>\n            <b>Descripción</b></br>\n            Esta función crea un perceptrón multicapa (MLP) y lo entrena. Los MLP son redes completamente conectadas de avance, y probablemente la arquitectura de red más común en uso. El entrenamiento generalmente se realiza mediante retropropagación de errores o un procedimiento relacionado.</br>\n            Hay muchas funciones de aprendizaje diferentes presentes en SNNS que se pueden usar junto con esta función, por ejemplo, Std_Backpropagation, BackpropBatch, BackpropChunk, BackpropMomentum, BackpropWeightDecay, Rprop, Quickprop, SCG (gradiente conjugado escalado), ...</br>\n            <b>Uso</b>\n            <br/>\n            <code> \n            mlp(x, ...)<br/>\n            ## Método S3 predeterminado:<br/>\n            mlp(x, y, size = c(5), maxit = 100,\n              initFunc = \"Randomize_Weights\", initFuncParams = c(-0.3, 0.3),\n              learnFunc = \"Std_Backpropagation\", learnFuncParams = c(0.2, 0),\n              updateFunc = \"Topological_Order\", updateFuncParams = c(0),\n              hiddenActFunc = \"Act_Logistic\", shufflePatterns = TRUE,\n              linOut = FALSE, outputActFunc = if (linOut) \"Act_Identity\" else\n              \"Act_Logistic\", inputsTest = NULL, targetsTest = NULL,\n              pruneFunc = NULL, pruneFuncParams = NULL, ...)\n            </code> <br/>\n            <b>Argumentos</b><br/>\n            <ul>\n            <li>\n            x: una matriz con entradas de entrenamiento para la red\n            </li>\n            <li>\n            ... : parámetros adicionales de la función (actualmente no utilizados)\n            </li>\n            <li>\n            y: los valores de destino correspondientes\n            </li>\n            <li>\n            size: número de unidades en la(s) capa(s) oculta(s)\n            </li>\n            <li>\n            maxit: máximo de iteraciones para aprender\n            </li>\n            <li>\n            initFunc: la función de inicialización a utilizar\n            </li>\n            <li>\n            initFuncParams: los parámetros para la función de inicialización\n            </li>\n            <li>\n            learnFunc: la función de aprendizaje a utilizar\n            </li>\n            <li>\n            learnFuncParams: los parámetros para la función de aprendizaje\n            </li>\n            <li>\n            updateFunc: la función de actualización a utilizar\n            </li>\n            <li>\n            updateFuncParams: los parámetros para la función de actualización\n            </li>\n            <li>\n            hiddenActFunc: la función de activación de todas las unidades ocultas\n            </li>\n            <li>\n            shufflePatterns: ¿deben mezclarse los patrones?\n            </li>\n            <li>\n            linOut: establece la función de activación de las unidades de salida a lineal o logística (ignorada si se proporciona outputActFunc)\n            </li>\n            <li>\n            outputActFunc: la función de activación de todas las unidades de salida\n            </li>\n            <li>\n            inputsTest: una matriz con entradas para probar la red\n            </li>\n            <li>\n            targetsTest: los objetivos correspondientes para la entrada de prueba\n            </li>\n            <li>\n            pruneFunc: la función de poda a utilizar\n            </li>\n            <li>\n            pruneFuncParams: los parámetros para la función de poda. A diferencia de las otras funciones, estos deben darse en una lista nombrada. Vea las demostraciones de poda para más explicaciones.\n            </li>\n            </ul>\n            <b>Detalles</b></br>\n            Std_Backpropagation, BackpropBatch, por ejemplo, tienen dos parámetros, la tasa de aprendizaje y la diferencia máxima de salida. La tasa de aprendizaje suele ser un valor entre 0.1 y 1. Especifica el ancho del paso de descenso de gradiente. La diferencia máxima define cuánto se trata la diferencia entre el valor de salida y el valor objetivo como error cero, y no se retropropaga. Este parámetro se utiliza para prevenir el sobreentrenamiento. Para una lista completa de los parámetros de todas las funciones de aprendizaje, consulte el Manual del Usuario de SNNS, pp. 67.</br>\n            Los valores predeterminados que se establecen para las funciones de inicialización y actualización generalmente no necesitan ser cambiados.</br>\n            <b>Valor</b><br/>\n            un objeto rsnns.\n            <b>Referencias</b><br/>\n            Rosenblatt, F. (1958), 'El perceptrón: un modelo probabilístico para el almacenamiento y organización de información en el cerebro', Psychological Review 65(6), 386–408.<br/>\n            Rumelhart, D. E.; Clelland, J. L. M. & Group, P. R. (1986), Procesamiento distribuido en paralelo: exploraciones en la microestructura de la cognición, Mit, Cambridge, MA, etc.<br/>\n            Zell, A. et al. (1998), 'Manual del Usuario del Simulador de Redes Neuronales SNNS, Versión 4.2', IPVR, Universidad de Stuttgart y WSI, Universidad de Tübingen.<br/> http://www.ra.cs.uni-tuebingen.de/SNNS/welcome.html<br/>\n            Zell, A. (1994), Simulación de Redes Neuronales, Addison-Wesley. (en alemán)<br/>\n            <b>Ejemplos</b><br/>\n            <code> \n            data(iris)<br/>\n            #mezclar el vector<br/>\n            iris <- iris[sample(1:nrow(iris),length(1:nrow(iris))),1:ncol(iris)]<br/>\n            irisValues <- iris[,1:4]<br/>\n            irisTargets <- decodeClassLabels(iris[,5])<br/>\n            #irisTargets <- decodeClassLabels(iris[,5], valTrue=0.9, valFalse=0.1)<br/>\n            iris <- splitForTrainingAndTest(irisValues, irisTargets, ratio=0.15)<br/>\n            iris <- normTrainingAndTestSet(iris)<br/>\n            model <- mlp(iris$inputsTrain, iris$targetsTrain, size=5, learnFuncParams=c(0.1),\n                          maxit=50, inputsTest=iris$inputsTest, targetsTest=iris$targetsTest)<br/>\n            summary(model)<br/>\n            model<br/>\n            weightMatrix(model)<br/>\n            extractNetInfo(model)<br/>\n            par(mfrow=c(2,2))<br/>\n            plotIterativeError(model)<br/>\n            predictions <- predict(model,iris$inputsTest)<br/>\n            plotRegressionError(predictions[,2], iris$targetsTest[,2])<br/>\n            confusionMatrix(iris$targetsTrain,fitted.values(model))<br/>\n            confusionMatrix(iris$targetsTest,predictions)<br/>\n            plotROC(fitted.values(model)[,2], iris$targetsTrain[,2])<br/>\n            plotROC(predictions[,2], iris$targetsTest[,2])<br/>\n            #matriz de confusión con el método 402040<br/>\n            confusionMatrix(iris$targetsTrain, encodeClassLabels(fitted.values(model),\n                                                                   method=\"402040\", l=0.4, h=0.6))<br/>\n            </code> <br/>\n            <b>Paquete</b></br>\n            RSNNS;NeuralNetTools</br>\n            <b>Ayuda</b></br>\n            Para ayuda detallada, haga clic en el ícono de R en la parte superior derecha de este diálogo o ejecute el siguiente comando en el editor de sintaxis de R</br>\n            help(mlp, package ='RSNNS')\n\t\t\t"
  }
}
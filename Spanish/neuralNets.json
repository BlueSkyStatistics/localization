{
  "title": "Entrenamiento de Redes Neuronales, usando el paquete neuralnet",
  "navigation": "Redes Neuronales",
  "label1": "POR FAVOR CODIFIQUE VARIABLES FACTOR DUMMY, VEA DATOS > CALCULAR VARIABLES DUMMY (MANTENER TODOS LOS NIVELES A.K.A CODIFICACIÓN ONE HOT). ESCALAR Y CENTRAR VARIABLES NUMÉRICAS, VEA DATOS > ESTANDARIZAR VARIABLES",
  "model": "Ingrese un nombre de modelo",
  "dependentvar": "Variable dependiente",
  "independentvars": "Variable(s) independiente(s)",
  "seed": "Establecer semilla",
  "iter": "Máximos pasos para el aprendizaje",
  "tf": "Algoritmo",
  "threshold": "Umbral",
  "label2": "Número de capas ocultas y neuronas por capa oculta",
  "layers": "Especifique el número de neuronas en cada capa, por ejemplo 1. Para 5 neuronas en 1 capa, ingrese 5. Para 5 neuronas en la capa 1, 6 neuronas en la capa 2, 7 neuronas en la capa 3 ingrese 5,6,7",
  "OutActFunc": "Especifique una función de activación de salida",
  "rep": "Repeticiones para el entrenamiento de la red neuronal",
  "label3": "Factores de multiplicación para la tasa de aprendizaje superior e inferior",
  "minus": "Superior (menos)",
  "upper": "Inferior (más)",
  "lifesign": "Configuración de cuánto imprimir durante el cálculo de la red neuronal",
  "lifesignstep": "Tamaño de paso para imprimir el umbral mínimo en modo de vida completo",
  "errfct": "Función diferenciable utilizada para el cálculo del error",
  "linearoutput": "La función de activación no debe aplicarse a las neuronas de salida",
  "likelihood": "Verosimilitud",
  "help": {
    "title": "Entrenamiento de Redes Neuronales, usando el paquete neuralnet",
    "r_help": "help(neuralnet, package='neuralnet')",
    "body": "\n            <b>NOTA</b></br>\n            Al especificar una sola variable dependiente, puede ser numérica o factor. Si la variable dependiente especificada es un factor, codificamos automáticamente la variable factor utilizando codificación one-hot usando la función decode en el paquete RSNNS.</br></br>\n            Además, si está utilizando codificación one-hot para codificar una variable factor, puede especificar más de una variable dependiente en el diálogo. En este caso, las variables dependientes deben ser de tipo numérico.</br></br>\n            Puede usar \"Datos > Calcular variables dummy\", elija la configuración “Mantener todos los niveles” para obtener codificación one-hot.</br></br>\n            Para variables dependientes de tipo factor, mostraremos una matriz de confusión, ROC y estadísticas de precisión del modelo al puntuar un conjunto de datos utilizando el modelo construido. Las predicciones generadas son de tipo factor ya que predecimos la clase. Estas se guardarán en el conjunto de datos junto con las probabilidades predichas al puntuar.</br></br>\n            Cuando hay variables dependientes codificadas como dummy, no mostraremos una matriz de confusión, ROC y estadísticas de precisión del modelo al puntuar un conjunto de datos utilizando el modelo construido. Sin embargo, las predicciones se guardarán en el conjunto de datos al puntuar el conjunto de datos. Las predicciones son las probabilidades asociadas con las variables dependientes codificadas como dummy.</br></br>\n            Generalmente es mejor estandarizar las variables independientes (también deben ser numéricas) Vea “Datos > Estandarizar Variables.”</br></br>\n            Si tiene variables independientes categóricas, use codificación one-hot para codificar las variables factor.</br></br>\n            <b>Descripción</b></br>\n            Entrene redes neuronales utilizando retropropagación, retropropagación resistente (RPROP) con (Riedmiller, 1994) o sin retroceso de peso (Riedmiller y Braun, 1993) o la versión modificada globalmente convergente (GRPROP) de Anastasiadis et al. (2005). La función permite configuraciones flexibles a través de la elección personalizada de la función de error y la función de activación. Además, se implementa el cálculo de pesos generalizados (Intrator O. e Intrator N., 1993).\n            <b>Uso</b>\n            <br/>\n            <code> \n            neuralnet(formula, data, hidden = 1, threshold = 0.01,\n              stepmax = 1e+05, rep = 1, startweights = NULL,\n              learningrate.limit = NULL, learningrate.factor = list(minus = 0.5,\n              plus = 1.2), learningrate = NULL, lifesign = \"none\",\n              lifesign.step = 1000, algorithm = \"rprop+\", err.fct = \"sse\",\n              act.fct = \"logistic\", linear.output = TRUE, exclude = NULL,\n              constant.weights = NULL, likelihood = FALSE)\n            </code> <br/>\n            <b>Argumentos</b><br/>\n            <ul>\n            <li>\n            formula: una descripción simbólica del modelo a ajustar.\n            </li>\n            <li>\n            data: un marco de datos que contiene las variables especificadas en la fórmula.\n            </li>\n            <li>\n            hidden: un vector de enteros que especifica el número de neuronas ocultas (vértices) en cada capa.\n            </li>\n            <li>\n            threshold: un valor numérico que especifica el umbral para las derivadas parciales de la función de error como criterio de detención.\n            </li>\n            <li>\n            stepmax: los pasos máximos para el entrenamiento de la red neuronal. Alcanzar este máximo lleva a una detención del proceso de entrenamiento de la red neuronal.\n            </li>\n            <li>\n            rep: el número de repeticiones para el entrenamiento de la red neuronal.\n            </li>\n            <li>\n            startweights: un vector que contiene valores iniciales para los pesos. Establecer en NULL para inicialización aleatoria.\n            </li>\n            <li>\n            learningrate.limit: un vector o una lista que contiene el límite más bajo y más alto para la tasa de aprendizaje. Usado solo para RPROP y GRPROP.</li>\n            <li>\n            learningrate.factor: un vector o una lista que contiene los factores de multiplicación para la tasa de aprendizaje superior e inferior. Usado solo para RPROP y GRPROP.\n            </li>\n            <li>\n            learningrate: un valor numérico que especifica la tasa de aprendizaje utilizada por la retropropagación tradicional. Usado solo para la retropropagación tradicional.\n            </li>\n            <li>\n            lifesign: una cadena que especifica cuánto imprimirá la función durante el cálculo de la red neuronal. 'none', 'minimal' o 'full'.\n            </li>\n            <li>\n            lifesign.step: un entero que especifica el tamaño de paso para imprimir el umbral mínimo en modo de vida completo.\n            </li>\n            <li>\n            algorithm: una cadena que contiene el tipo de algoritmo para calcular la red neuronal. Los siguientes tipos son posibles: 'backprop', 'rprop+', 'rprop-', 'sag', o 'slr'. 'backprop' se refiere a la retropropagación, 'rprop+' y 'rprop-' se refieren a la retropropagación resistente con y sin retroceso de peso, mientras que 'sag' y 'slr' inducen el uso del algoritmo modificado globalmente convergente (grprop). Vea Detalles para más información.\n            </li>\n            <li>\n            err.fct: una función diferenciable que se utiliza para el cálculo del error. Alternativamente, se pueden usar las cadenas 'sse' y 'ce' que representan la suma de errores cuadrados y la entropía cruzada.\n            </li>\n            <li>\n            act.fct: una función diferenciable que se utiliza para suavizar el resultado del producto cruzado de la covariable o neuronas y los pesos. Además, las cadenas 'logistic' y 'tanh' son posibles para la función logística y la tangente hiperbólica.\n            </li>\n            <li>\n            linear.output: lógico. Si la función act.fct no debe aplicarse a las neuronas de salida, establezca la salida lineal en TRUE, de lo contrario en FALSE.\n            </li>\n            <li>\n            exclude: un vector o una matriz que especifica los pesos que se excluyen del cálculo. Si se da como un vector, deben conocerse las posiciones exactas de los pesos. Una matriz con n filas y 3 columnas excluirá n pesos, donde la primera columna representa la capa, la segunda columna el neurona de entrada y la tercera columna el neurona de salida del peso.\n            </li>\n            <li>\n            constant.weights: un vector que especifica los valores de los pesos que se excluyen del proceso de entrenamiento y se tratan como fijos.\n            </li>\n            <li>\n            likelihood: lógico. Si la función de error es igual a la función de verosimilitud negativa, se calcularán los criterios de información AIC y BIC. Además, el uso de confidence.interval es significativo.\n            </li>\n            </ul>\n            <b>Detalles</b><br/>\n            El algoritmo globalmente convergente se basa en la retropropagación resistente sin retroceso de peso y además modifica una tasa de aprendizaje, ya sea la tasa de aprendizaje asociada con el gradiente absoluto más pequeño (sag) o la tasa de aprendizaje más pequeña (slr) en sí misma. Las tasas de aprendizaje en el algoritmo grprop están limitadas a los límites definidos en learningrate.limit.\n            ​<b>Valor</b><br/>\n            neuralnet devuelve un objeto de clase nn. Un objeto de clase nn es una lista que contiene como máximo los siguientes componentes:<br/>\n            call: la llamada coincidente.<br/>\n            response: extraído del argumento de datos.<br/>\n            covariate: las variables extraídas del argumento de datos.<br/>\n            model.list: una lista que contiene las covariables y las variables de respuesta extraídas del argumento de fórmula.<br/>\n            err.fct: la función de error.<br/>\n            act.fct: la función de activación.<br/>\n            data: el argumento de datos.<br/>\n            net.result: una lista que contiene el resultado general de la red neuronal para cada repetición.<br/>\n            weights: una lista que contiene los pesos ajustados de la red neuronal para cada repetición.<br/>\n            generalized.weights: una lista que contiene los pesos generalizados de la red neuronal para cada repetición.<br/>\n            result.matrix: una matriz que contiene el umbral alcanzado, pasos necesarios, error, AIC y BIC (si se calcula) y pesos para cada repetición. Cada columna representa una repetición.<br/>\n            startweights: una lista que contiene los pesos iniciales de la red neuronal para cada repetición.<br/>\n            ​<b>Ejemplos</b><br/>\n            <code> \n            ​library(neuralnet)\n            ​# Clasificación binaria\n            nn <- neuralnet(Species == \"setosa\" ~ Petal.Length + Petal.Width, iris, linear.output = FALSE)\n            ## No ejecutado: print(nn)\n            ## No ejecutado: plot(nn)\n            # Clasificación multiclase\n            nn <- neuralnet(Species ~ Petal.Length + Petal.Width, iris, linear.output = FALSE)\n            ## No ejecutado: print(nn)\n            ## No ejecutado: plot(nn)\n            # Función de activación personalizada\n            softplus <- function(x) log(1 + exp(x))\n            nn <- neuralnet((Species == \"setosa\") ~ Petal.Length + Petal.Width, iris, \n                            linear.output = FALSE, hidden = c(3, 2), act.fct = softplus)\n            ## No ejecutado: print(nn)\n            ## No ejecutado: plot(nn)\n            </code> <br/>\n            <b>Paquete</b></br>\n            neuralnet;NeuralNetTools</br>\n            <b>Ayuda</b></br>\n            Para ayuda detallada, haga clic en el ícono de R en la parte superior derecha de este diálogo o ejecute el siguiente comando en el editor de sintaxis de R</br>\n            help(neuralnet, package='neuralnet')\n\t\t\t"
  }
}